# 人工智能：60 年来的第一个新 UI 范式

> [原文链接](https://www.nngroup.com/articles/ai-paradigm/)

[ChatGPT](https://www.nngroup.com/articles/chatgpt-productivity/)和其他人工智能系统正在形成计算历史上第三种用户界面范式 - 超过 60 年来的第一个新的交互模型。

## 前两个范式

### 范式 1：批处理

从计算机诞生开始，大约**1945 年**，第一个 UI 范式是批处理。在这种范式中，用户指定了他们希望计算机执行的所有工作流程。这批指令被提交到数据中心（通常作为一叠打孔卡片）并在某个未指定的时间处理，通常是在夜间。

随后，通常第二天早上，用户会拿起他们的批处理输出：通常是一叠厚厚的打印输出，但也可能是一叠新的打孔卡片。如果原始批处理中有任何微小错误，将没有输出，或者结果将毫无意义。

从用户界面的角度来看，批处理不涉及用户和计算机之间的来回交流。用户界面是一个单一的接触点：一批打孔卡片。可用性很差，通常需要多天的时间来微调批处理，直到执行它会产生期望的最终结果。

### 范式 2：基于命令的交互设计

大约**1964 年**，分时共享的出现（多个用户通过连接的终端共享单个大型机计算机）导致了第二个 UI 范式：基于命令的交互。在这种范式中，用户和计算机轮流，一次执行一个命令。这种范式如此强大，以至于自那时起一直主导着计算 - 超过 60 年。

基于命令的交互一直是用户界面技术的基本方法：命令行（如 DOS 和 Unix）、全屏文本终端（与 IBM 大型机常见）、[图形用户界面](https://www.nngroup.com/articles/direct-manipulation/)（GUI：Macintosh、Windows 和所有当前智能手机平台）。确实强大且持久。

与批处理相比，基于命令的交互的好处是明显的：在执行每个命令后，**用户可以重新评估情况并修改未来的命令**以朝着期望的目标前进。

实际上，用户甚至不需要心中有一个完全明确的目标，因为他们可以根据从计算机获取的更多信息以及看到初始命令的结果来调整解决问题的方法。 （至少，如果设计遵循了[10 个可用性启发式](https://www.nngroup.com/articles/ten-usability-heuristics/)中的第一个：系统状态的可见性。）早期的命令行系统通常不显示系统的当前状态，结果可想而知的可用性很差。例如，在 Unix 中，没有消息就是好消息，因为只有在您的命令导致错误消息时才会从计算机获得反馈。没有错误意味着没有关于新状态的计算机信息，这使用户更难以组合下一个命令。

图形用户界面的美妙之处在于，它们至少在每个命令之后显示状态，至少在设计良好时是这样。自 1984 年 Macintosh 推出以来，**图形用户界面一直主导着用户体验世界**：大约 40 年的统治，直到可能被下一代 UI 技术和更重要的是以人工智能形式的下一个 UI 范式所取代。

## 最新的范式

### 范式 3：基于意图的结果规范

我怀疑当前一套生成式 AI 工具（如 ChatGPT、Bard 等）并不代表我们未来几年将使用的 UI，因为**它们存在根深蒂固的可用性问题**。它们的问题导致了一个新角色的产生——“提示工程师”。提示工程师的存在是为了在正确的位置刺激 ChatGPT，以便它产生正确的结果。

这种新角色让我想起我们过去需要经过专门培训的查询专家来搜索大量医学研究或法律案例数据库。然后谷歌出现了，任何人都可以搜索。这些新工具需要同样级别的可用性飞跃：**AI 的更好可用性应该是一个重要的竞争优势。**（如果你考虑成为提示工程师，不要指望有一个持久的职业。）

当前基于聊天的交互方式也存在问题，需要用户将问题写成散文文本。根据最近的识字研究，我认为在富裕国家，[一半的人口不够表达](https://www.linkedin.com/pulse/prompt-driven-ai-ux-hurts-usability-jakob-nielsen/)，无法从当前的 AI 机器人中获得良好的结果。

话虽如此，**AI 用户界面**代表了人类和计算机之间互动的不同范式——这是一个充满希望的范式。

正如我所提到的，在基于命令的交互中，用户逐步向计算机发出命令，逐步产生期望的结果（如果设计具有足够的可用性，使人们能够理解在每个步骤发出什么命令）。计算机完全服从并且完全按照指示行事。缺点是低可用性经常导致用户发出与他们真正想要的不同的命令。

在新的 AI 系统中，用户不再告诉计算机要**做什么**。相反，用户告诉计算机他们想要的结果。因此，**第三个 UI 范式，由当前生成式 AI 代表，是**基于意图的结果规范**。

一个 AI 系统的提示的简单示例是：

> *为一本低俗科幻杂志的封面制作一幅图，展示一个穿着太空服的牛仔在一个无空气的行星上，天空中有两个红色的月亮。*

试着让 2021 年的 Photoshop 做到这一点！那时，你可能需要发出数百个命令逐渐呈现插图。今天，必应图像创建者在几秒钟内为我生成了四幅建议的图像。

![](img/267e3cf09adf1e791ff11cfbab87e544.png)

*由必应图像创建者生成的图像* *从提示“为一本低俗科幻杂志的封面制作一幅图，展示一个穿着太空服的牛仔在一个无空气的行星上，天空中有两个红色的月亮。”*

通过当前生成式 AI 代表的这种新 UI 范式，用户告诉计算机期望的结果，但不指定应该如何实现这个结果。与传统的基于命令的交互相比，这种范式**完全颠倒了控制的中心**。我怀疑我们甚至不应该将这种用户体验描述为“交互”，因为没有轮流或逐渐进展。

话虽如此，在我的科幻插图示例中，我对太空服不满意。这可能通过与 AI 的另一轮修正来解决。这种逐步完善的轮次是一种目前支持不足的交互形式，为那些**愿意进行用户研究**以发现更好的方法让普通人控制他们的系统提供了丰富的可用性改进机会的 AI 供应商。

“做我想要的，而不是我说的”是一种诱人的 UI 范式 - 正如前面提到的，用户经常命令计算机做错误的事情。另一方面，完全将控制权交给计算机也有缺点，特别是在当前的 AI 中，它倾向于在结果中包含错误信息。当用户不知道某件事是如何完成的时，他们可能更难识别或纠正问题。

基于意图的范式并没有达到我在 1993 年引入的非命令系统的水平。真正的非命令系统不需要用户指定意图，因为计算机是用户正常操作的副作用。

举个例子，考虑通过拉门把手解锁汽车：这是一个非命令解锁，因为用户无论汽车是锁着还是解锁状态都会执行相同的操作。（相比之下，通过语音识别操作的汽车可以解锁车门，因为用户说过“我想要解锁车辆”，这将是一个基于意图的结果规范。而传统的汽车可以通过明确的命令来解锁车门，即插入并转动钥匙。）

AI 系统能否在基于意图的结果规范范式中实现高可用性尚不清楚。我对此表示怀疑，因为我是图形用户界面的热情粉丝。视觉信息通常比文本更容易理解，交互速度更快。你能通过与聊天机器人对话来填写长表格（比如银行账户申请或酒店预订）吗？即使是像新的生成式 AI 工具这样聪明的聊天机器人？

点击或轻触屏幕上的东西是用户交互的直观和基本方面，不应被忽视。因此，第二个 UI 范式将会存活下来，尽管在一个不那么主导的角色中。未来的 AI 系统可能会有一个混合用户界面，结合了基于意图和基于命令的接口元素，同时仍保留许多 GUI 元素。
