- en: Cheating is All You Need
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½œå¼Šå°±æ˜¯ä½ æ‰€éœ€è¦çš„
- en: 'Original Text: [https://about.sourcegraph.com/blog/cheating-is-all-you-need](https://about.sourcegraph.com/blog/cheating-is-all-you-need)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://about.sourcegraph.com/blog/cheating-is-all-you-need](https://about.sourcegraph.com/blog/cheating-is-all-you-need)
- en: Heya. Sorry for not writing for so long. Iâ€™ll make up for it with 3000 pages
    here.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: å˜¿ã€‚å¾ˆæŠ±æ­‰å¾ˆä¹…æ²¡æœ‰å†™ä¸œè¥¿äº†ã€‚æˆ‘ä¼šåœ¨è¿™é‡Œå¼¥è¡¥ï¼Œå†™ 3000 é¡µã€‚
- en: Iâ€™m just hopping right now. Thatâ€™s kinda the only way to get me to blog anymore.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç°åœ¨åªæ˜¯åœ¨è·³è·ƒã€‚è¿™å¯èƒ½æ˜¯å”¯ä¸€è®©æˆ‘å†å†™åšå®¢çš„æ–¹å¼ã€‚
- en: Iâ€™ve rewritten this post so many times. Itâ€™s about AI. But AI is changing so
    fast that the post is out of date within a few days. So screw it. Iâ€™m busting
    this version out in one sitting.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å·²ç»é‡å†™äº†è¿™ç¯‡æ–‡ç« å¾ˆå¤šæ¬¡äº†ã€‚å®ƒæ˜¯å…³äºäººå·¥æ™ºèƒ½çš„ã€‚ä½†æ˜¯äººå·¥æ™ºèƒ½å‘å±•å¾—å¦‚æ­¤ä¹‹å¿«ï¼Œä»¥è‡³äºè¿™ç¯‡æ–‡ç« åœ¨å‡ å¤©å†…å°±è¿‡æ—¶äº†ã€‚æ‰€ä»¥ç®—äº†ã€‚æˆ‘ä¸€å£æ°”å†™å‡ºè¿™ä¸ªç‰ˆæœ¬ã€‚
- en: '*(Spoiler alert: Thereâ€™s some Sourcegraph stuff at the end, including a product
    plug and some recruiting stuff. But >80% of this post is just about LLMsâ€“GPT etc.â€“and
    you, a programmer.)*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*(å‰§é€è­¦å‘Šï¼šæœ¬æ–‡æœ«å°¾åŒ…å«ä¸€äº› Sourcegraph çš„å†…å®¹ï¼ŒåŒ…æ‹¬äº§å“æ¨å¹¿å’Œæ‹›è˜å†…å®¹ã€‚ä½†æœ¬æ–‡è¶…è¿‡ 80% çš„å†…å®¹åªæ˜¯å…³äº LLMsâ€“GPT ç­‰ç­‰â€“å’Œä½ ï¼Œä¸€ä¸ªç¨‹åºå‘˜ã€‚)*'
- en: There is something **legendary and historic** happening in software engineering,
    right now as we speak, and yet most of you donâ€™t realize at all how big it is.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£åœ¨å‘ç”Ÿä¸€äº›**ä¼ å¥‡å’Œå†å²æ€§**çš„äº‹æƒ…åœ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸï¼Œå°±åœ¨æˆ‘ä»¬è¯´è¯çš„æ­¤åˆ»ï¼Œç„¶è€Œå¤§å¤šæ•°äººæ ¹æœ¬æ²¡æœ‰æ„è¯†åˆ°è¿™æœ‰å¤šä¹ˆé‡è¦ã€‚
- en: LLMs arenâ€™t just the biggest change since social, mobile, or cloudâ€“theyâ€™re the
    biggest thing since the World Wide Web. And on the coding front, theyâ€™re the biggest
    thing since IDEs and Stack Overflow, and may well eclipse them both.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs ä¸ä»…æ˜¯ç¤¾äº¤ã€ç§»åŠ¨æˆ–äº‘ä¹‹åçš„æœ€å¤§å˜é©â€“å®ƒä»¬æ˜¯è‡ªä¸‡ç»´ç½‘ä»¥æ¥æœ€é‡è¦çš„äº‹æƒ…ã€‚åœ¨ç¼–ç æ–¹é¢ï¼Œå®ƒä»¬æ˜¯è‡ªé›†æˆå¼€å‘ç¯å¢ƒå’Œ Stack Overflow ä»¥æ¥æœ€é‡è¦çš„äº‹æƒ…ï¼Œè€Œä¸”å¾ˆå¯èƒ½ä¼šè¶…è¶Šå®ƒä»¬ã€‚
- en: But most of the engineers I *personally* know are sort of squinting at it and
    thinking, â€œIs this another crypto?â€ Even the devs at Sourcegraph are skeptical.
    I mean, what engineer isnâ€™t. Being skeptical is a survival skill.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æˆ‘**ä¸ªäºº**è®¤è¯†çš„å¤§å¤šæ•°å·¥ç¨‹å¸ˆéƒ½æœ‰ç‚¹çœ¯ç€çœ¼çœ‹ç€å®ƒï¼Œæƒ³ç€ï¼Œâ€œè¿™æ˜¯åˆä¸€ä¸ªåŠ å¯†è´§å¸å—ï¼Ÿâ€å³ä½¿æ˜¯ Sourcegraph çš„å¼€å‘äººå‘˜ä¹ŸæŒæ€€ç–‘æ€åº¦ã€‚æˆ‘æ˜¯è¯´ï¼Œå“ªä¸ªå·¥ç¨‹å¸ˆä¸æ˜¯å‘¢ã€‚æŒæ€€ç–‘æ€åº¦æ˜¯ä¸€ç§ç”Ÿå­˜æŠ€èƒ½ã€‚
- en: Remember I told you how my Amazon shares would have been worth $130 million
    USD today if I hadnâ€™t been such a *skeptic* about how big Amazon was going to
    get, and unloaded them all back in 2004-ish. Right? I told you about that? Iâ€™m
    sure I mentioned it once or twice. Not that I am bitter. No.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è®°å¾—æˆ‘å‘Šè¯‰è¿‡ä½ å—ï¼Œå¦‚æœæˆ‘å½“æ—¶æ²¡æœ‰å¯¹äºšé©¬é€Šçš„è§„æ¨¡æŒæ€€ç–‘æ€åº¦ï¼Œå¹¶åœ¨å¤§çº¦ 2004 å¹´å‡ºå”®äº†æ‰€æœ‰è‚¡ä»½ï¼Œé‚£ä¹ˆæˆ‘çš„äºšé©¬é€Šè‚¡ä»½ä»Šå¤©å¯èƒ½ä»·å€¼ 1.3 äº¿ç¾å…ƒã€‚å¯¹å§ï¼Ÿæˆ‘å‘Šè¯‰è¿‡ä½ è¿™ä»¶äº‹å—ï¼Ÿæˆ‘è‚¯å®šæè¿‡ä¸€ä¸¤æ¬¡ã€‚æˆ‘å¹¶ä¸æ˜¯åœ¨æŠ±æ€¨ã€‚æ²¡æœ‰ã€‚
- en: But did I ever tell you about the time AWS was just a demo on some engineerâ€™s
    laptop? No? Well it was [Ruben Ortega](https://www.linkedin.com/in/rubeneortega/)
    and [Al Vermeulen](https://www.linkedin.com/in/allan-vermeulen-58835b/). They
    were walking around the eng department at Amazon, showing their â€œweb serviceâ€
    demo to anyone whoâ€™d watch it. This was back in maybeâ€¦ 2003? Ish? They showed
    us how you could make a service call over the web, like by hitting a URL and sending
    the right query parameters.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æˆ‘æœ‰æ²¡æœ‰å‘Šè¯‰è¿‡ä½  AWS æ›¾ç»åªæ˜¯æŸä¸ªå·¥ç¨‹å¸ˆç¬”è®°æœ¬ä¸Šçš„æ¼”ç¤ºï¼Ÿæ²¡æœ‰ï¼Ÿé‚£ä¹ˆå°±æ˜¯ [Ruben Ortega](https://www.linkedin.com/in/rubeneortega/)
    å’Œ [Al Vermeulen](https://www.linkedin.com/in/allan-vermeulen-58835b/)ã€‚ä»–ä»¬åœ¨äºšé©¬é€Šçš„å·¥ç¨‹éƒ¨é—¨é‡Œèµ°æ¥èµ°å»ï¼Œå‘ä»»ä½•æ„¿æ„çœ‹çš„äººå±•ç¤ºä»–ä»¬çš„â€œç½‘ç»œæœåŠ¡â€æ¼”ç¤ºã€‚å¤§æ¦‚æ˜¯åœ¨â€¦2003å¹´ï¼Ÿå·¦å³ï¼Ÿä»–ä»¬å‘æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ç½‘ç»œè¿›è¡ŒæœåŠ¡è°ƒç”¨ï¼Œæ¯”å¦‚é€šè¿‡è®¿é—®
    URL å¹¶å‘é€æ­£ç¡®çš„æŸ¥è¯¢å‚æ•°ã€‚
- en: Well lo and behold we were *skeptical*. Why the hell would you make a service
    call over the web? Thatâ€™s not what it was even designed for! Not to mention, it
    *obviously* wouldnâ€™t perform as well as CORBA (Amazonâ€™s stupid-ass RPC system
    at the time). The whole thing just didnâ€™t make any sense to us.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å“¦ï¼Œæˆ‘ä»¬å½“æ—¶æ˜¯*æŒæ€€ç–‘æ€åº¦*çš„ã€‚ä¸ºä»€ä¹ˆè¦é€šè¿‡ç½‘ç»œè¿›è¡ŒæœåŠ¡è°ƒç”¨å‘¢ï¼Ÿè¿™ç”šè‡³ä¸æ˜¯å®ƒè®¾è®¡çš„åˆè¡·ï¼æ›´ä¸ç”¨è¯´ï¼Œå®ƒæ˜¾ç„¶ä¸ä¼šåƒ CORBAï¼ˆå½“æ—¶äºšé©¬é€Šæ„šè ¢çš„ RPC ç³»ç»Ÿï¼‰é‚£æ ·é«˜æ•ˆã€‚æ•´ä»¶äº‹å¯¹æˆ‘ä»¬æ¥è¯´æ ¹æœ¬æ¯«æ— æ„ä¹‰ã€‚
- en: We were seeing the first little flecks of lava from what would become a trillion-dollar
    volcano of money called AWS and Cloud Computing.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°äº†ç¬¬ä¸€ç¼•ä» AWS å’Œäº‘è®¡ç®—ä¸­æ¶Œç°å‡ºçš„å°†æˆä¸ºä¸€ä¸ªä¸‡äº¿ç¾å…ƒé‡‘é’±ç«å±±çš„å²©æµ†ã€‚
- en: But a lot of us were skeptical. To most of us, those little lava flecks looked
    like fireflies.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¾ˆå¤šäººå¯¹æ­¤æŒæ€€ç–‘æ€åº¦ã€‚å¯¹äºæˆ‘ä»¬å¤§å¤šæ•°äººæ¥è¯´ï¼Œé‚£äº›å°å°çš„å²©æµ†çœ‹èµ·æ¥åƒè¤ç«è™«ã€‚
- en: '[](#the-ultra-rare-trillion-dollar-money-volcano)The ultra-rare trillion-dollar
    money volcano'
  id: totrans-14
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#the-ultra-rare-trillion-dollar-money-volcano)è¶…ç¨€æœ‰çš„ä¸‡äº¿ç¾å…ƒé‡‘é’±ç«å±±'
- en: I could tell you a LOT of stories like the web-services one. Great big shit
    always starts life as a demo.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥å‘Šè¯‰ä½ å¾ˆå¤šåƒç½‘ç»œæœåŠ¡è¿™æ ·çš„æ•…äº‹ã€‚æ‰€æœ‰ä¼Ÿå¤§çš„äº‹æƒ…æ€»æ˜¯ä»æ¼”ç¤ºå¼€å§‹çš„ã€‚
- en: 'What about chatting with people in a browser? Doesnâ€™t matter whether youâ€™re
    using Facebook, Google Chat, LinkedIn, or just chatting with a customer service
    agent: if youâ€™re having a conversation with someone in a browser, all that shit
    started life as a teeny demo of 2 engineers sending messages back and forth over
    a â€œhanging GETâ€ channel back in 2005\. Entire *industries* were built on that
    one little channel, and it wasnâ€™t even very good.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æµè§ˆå™¨ä¸­ä¸äººèŠå¤©æ€ä¹ˆæ ·ï¼Ÿæ— è®ºä½ æ˜¯ä½¿ç”¨Facebookã€Google Chatã€LinkedInï¼Œè¿˜æ˜¯åªæ˜¯ä¸å®¢æœä»£è¡¨èŠå¤©ï¼šå¦‚æœä½ åœ¨æµè§ˆå™¨ä¸­ä¸æŸäººå¯¹è¯ï¼Œæ‰€æœ‰è¿™äº›ä¸œè¥¿éƒ½å§‹äº2005å¹´ä¸¤åå·¥ç¨‹å¸ˆåœ¨â€œæŒ‚èµ·GETâ€é€šé“ä¸Šæ¥å›å‘é€æ¶ˆæ¯çš„ä¸€ä¸ªå¾®å°æ¼”ç¤ºã€‚æ•´ä¸ª*è¡Œä¸š*éƒ½æ˜¯å»ºç«‹åœ¨é‚£ä¸ªå¾®å°é€šé“ä¸Šçš„ï¼Œè€Œä¸”å®ƒç”šè‡³ä¸æ˜¯å¾ˆå¥½ã€‚
- en: What about Kubernetes? I remember seeing a demo of that early on, on Brendan
    Burnsâ€™ work laptop, when it was called mini-Borg. Entire *industries* are being
    built on Kubernetes, and itâ€™s not even very good either. ğŸ˜‰ Or look at Docker!
    Something as innocuous as linux cgroups, a little process-isolation manager, became
    the technical foundation for containers, which now utterly pervade our industry.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Kuberneteså‘¢ï¼Ÿæˆ‘è®°å¾—æ—©æœŸåœ¨Brendan Burnsçš„å·¥ä½œç¬”è®°æœ¬ä¸Šçœ‹åˆ°è¿‡ä¸€ä¸ªæ¼”ç¤ºï¼Œå½“æ—¶å®ƒè¢«ç§°ä¸ºmini-Borgã€‚æ•´ä¸ª*è¡Œä¸š*æ­£åœ¨åŸºäºKubernetesæ„å»ºï¼Œå¹¶ä¸”å®ƒç”šè‡³ä¹Ÿä¸æ˜¯å¾ˆå¥½ã€‚ğŸ˜‰
    å†çœ‹çœ‹Dockerï¼åƒLinux cgroupsè¿™æ ·æ— å®³çš„ä¸œè¥¿ï¼Œä¸€ä¸ªå°çš„è¿›ç¨‹éš”ç¦»ç®¡ç†å™¨ï¼Œæˆä¸ºäº†å®¹å™¨çš„æŠ€æœ¯åŸºç¡€ï¼Œç°åœ¨å®Œå…¨æ¸—é€äº†æˆ‘ä»¬çš„è¡Œä¸šã€‚
- en: If you can build something as big as Amazon Web Services with a stack based
    on a simple service call, or whole social networks and customer service suites
    based on simple browser-to-browser communication, or a robust way of delivering
    and managing software based on a little process isolation code, then just imagine
    how big a thing you could build â€“ bear with me here â€“ if you had the *goddamn
    Singularity* as your starting point?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯ä»¥é€šè¿‡åŸºäºç®€å•çš„æœåŠ¡è°ƒç”¨å †æ ˆæ„å»ºåƒAmazon Web Servicesè¿™æ ·å¤§çš„ä¸œè¥¿ï¼Œæˆ–è€…åŸºäºç®€å•çš„æµè§ˆå™¨åˆ°æµè§ˆå™¨é€šä¿¡æ„å»ºæ•´ä¸ªç¤¾äº¤ç½‘ç»œå’Œå®¢æˆ·æœåŠ¡å¥—ä»¶ï¼Œæˆ–è€…åŸºäºä¸€å°æ®µè¿›ç¨‹éš”ç¦»ä»£ç æ„å»ºä¸€ç§ç¨³å¥çš„è½¯ä»¶äº¤ä»˜å’Œç®¡ç†æ–¹å¼ï¼Œé‚£ä¹ˆæƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ ä»¥*è¯¥æ­»çš„å¥‡ç‚¹*ä½œä¸ºèµ·ç‚¹ï¼Œä½ å¯ä»¥æ„å»ºå¤šä¹ˆåºå¤§çš„ä¸œè¥¿ï¼Ÿ
- en: I mean, I joke, butâ€¦ I meanâ€¦ Right? Iâ€™m guessing you prolly missed it in OpenAIâ€™s
    98-page [GPT-4 technical report](https://cdn.openai.com/papers/gpt-4.pdf), but
    large models are apparently already prone to discovering that â€œpower-seekingâ€
    is an effective strategy for increasing their own robustness. Open the PDF and
    search for â€œpower-seekingâ€ for a fun and totally 100% non-scary [read](https://twitter.com/Suhail/status/1637952234913939460).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯è¯´ï¼Œæˆ‘å¼€ç©ç¬‘ï¼Œä½†æ˜¯... æˆ‘æ˜¯è¯´... å¯¹å§ï¼Ÿæˆ‘çŒœä½ å¯èƒ½åœ¨OpenAIçš„98é¡µ[GPT-4æŠ€æœ¯æŠ¥å‘Š](https://cdn.openai.com/papers/gpt-4.pdf)ä¸­å¯èƒ½é”™è¿‡äº†ï¼Œä½†æ˜¯å¤§å‹æ¨¡å‹æ˜¾ç„¶å·²ç»å€¾å‘äºå‘ç°â€œè¿½æ±‚æƒåŠ›â€æ˜¯å¢åŠ è‡ªèº«ç¨³å¥æ€§çš„æœ‰æ•ˆç­–ç•¥ã€‚æ‰“å¼€PDFå¹¶æœç´¢â€œè¿½æ±‚æƒåŠ›â€ä»¥è·å¾—æœ‰è¶£ä¸”å®Œå…¨ä¸å¯æ€•çš„é˜…è¯»[ä½“éªŒ](https://twitter.com/Suhail/status/1637952234913939460)ã€‚
- en: You can build truly massive things by building upon little technical breakthroughs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ©ç”¨ä¸€äº›å°çš„æŠ€æœ¯çªç ´ï¼Œä½ å¯ä»¥æ„å»ºçœŸæ­£åºå¤§çš„ä¸œè¥¿ã€‚
- en: And folks, this technical breakthrough? It ainâ€™t little.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‹å‹ä»¬ï¼Œè¿™ä¸ªæŠ€æœ¯çªç ´ï¼Ÿä¸€ç‚¹ä¹Ÿä¸å°ã€‚
- en: If youâ€™re not pant-peeingly excited *and* worried about this yet, wellâ€¦ you
    should be.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹æ­¤è¿˜æ²¡æœ‰å…´å¥‹åˆ°å°¿è£¤å­çš„ç¨‹åº¦*å¹¶ä¸”*æ‹…å¿ƒï¼Œé‚£ä¹ˆ... ä½ åº”è¯¥äº†è§£ä¸€ä¸‹ã€‚
- en: '[](#and-yet-the-mehs-prevail)And yet the Mehs prevail'
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#and-yet-the-mehs-prevail)ç„¶è€Œï¼Œå¹³åº¸å´å æ®ä¸»å¯¼åœ°ä½'
- en: 'We did an internal poll at Sourcegraph: Do you have positive sentiment or negative
    sentiment about LLMs for coding? Options were Positive, Negative, and Meh. And
    lo, it was about â…” Meh or Negative (i.e., Skeptics), which I suspect is fairly
    representative of the whole industry.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨Sourcegraphè¿›è¡Œäº†å†…éƒ¨æŠ•ç¥¨ï¼šä½ å¯¹LLMsç¼–ç æŒæœ‰ç§¯ææ€åº¦è¿˜æ˜¯æ¶ˆææ€åº¦ï¼Ÿé€‰é¡¹æ˜¯ç§¯æã€æ¶ˆæå’Œå¹³åº¸ã€‚ç»“æœå¤§çº¦æœ‰2/3çš„äººé€‰æ‹©äº†å¹³åº¸æˆ–æ¶ˆæï¼ˆå³ï¼Œæ€€ç–‘è€…ï¼‰ï¼Œæˆ‘è®¤ä¸ºè¿™ç›¸å½“ä»£è¡¨äº†æ•´ä¸ªè¡Œä¸šã€‚
- en: I asked around, and even as of a couple weeks ago, some devs questioned whether
    ChatGPT could even write *working* code, let alone write a full program by simply
    by telling it to write it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¯¢é—®äº†ä¸€ä¸‹ï¼Œç”šè‡³å°±åœ¨å‡ å‘¨å‰ï¼Œä¸€äº›å¼€å‘äººå‘˜è´¨ç–‘ChatGPTæ˜¯å¦èƒ½å¤Ÿç¼–å†™*å¯è¿è¡Œ*çš„ä»£ç ï¼Œæ›´ä¸ç”¨è¯´ä»…ä»…é€šè¿‡å‘Šè¯‰å®ƒæ¥ç¼–å†™ä¸€ä¸ªå®Œæ•´çš„ç¨‹åºäº†ã€‚
- en: So here I am, talking about money volcanoes, and my coworkers have formed a
    huge whirling meh-nado. Which natural disaster should you believe?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™é‡Œï¼Œæˆ‘åœ¨è°ˆè®ºé‡‘é’±ç«å±±ï¼Œè€Œæˆ‘çš„åŒäº‹ä»¬å·²ç»å½¢æˆäº†ä¸€ä¸ªå·¨å¤§çš„å¹³åº¸æ—‹é£ã€‚ä½ åº”è¯¥ç›¸ä¿¡å“ªç§è‡ªç„¶ç¾å®³ï¼Ÿ
- en: Well I mean, I guess a demo is worth a thousand mehs. Letâ€™s try it out.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œæˆ‘æ˜¯è¯´ï¼Œæˆ‘çŒœä¸€æ¬¡æ¼”ç¤ºèƒœè¿‡ä¸€åƒä¸ªå¹³åº¸ã€‚è®©æˆ‘ä»¬è¯•ä¸€è¯•ã€‚
- en: '[](#chatgpt-vs-emacs)ChatGPT vs Emacs'
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#chatgpt-vs-emacs)ChatGPTå¯¹æŠ—Emacs'
- en: Letâ€™s have ChatGPT write some Emacs-Lisp code. Iâ€™m picking emacs-lisp because
    itâ€™s a corner case language, bit of a stress test for the LLM, and because itâ€™s
    easy for me to try it out interactively.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è®©ChatGPTç¼–å†™ä¸€äº›Emacs-Lispä»£ç ã€‚æˆ‘é€‰æ‹©emacs-lispæ˜¯å› ä¸ºå®ƒæ˜¯ä¸€ä¸ªè¾¹ç¼˜æ¡ˆä¾‹è¯­è¨€ï¼Œå¯¹LLMæ¥è¯´æ˜¯ä¸€ç§å‹åŠ›æµ‹è¯•ï¼Œå¹¶ä¸”å› ä¸ºå¯¹æˆ‘æ¥è¯´å¾ˆå®¹æ˜“è¿›è¡Œäº¤äº’å¼å°è¯•ã€‚
- en: 'OK. I just typed this prompt into ChatGPT:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ã€‚æˆ‘åˆšåˆšåœ¨ChatGPTä¸­è¾“å…¥äº†è¿™ä¸ªæç¤ºï¼š
- en: '*> Write an interactive emacs-lisp function that pops to a new buffer, prints
    out the first paragraph of "A tale of two cities", and changes all words with
    ''i'' in them red. Just print the code without explanation.*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*> ç¼–å†™ä¸€ä¸ªäº¤äº’å¼çš„emacs-lispå‡½æ•°ï¼Œå¼¹å‡ºä¸€ä¸ªæ–°çš„ç¼“å†²åŒºï¼Œæ‰“å°å‡ºã€ŠåŒåŸè®°ã€‹çš„ç¬¬ä¸€æ®µï¼Œå¹¶å°†æ‰€æœ‰åŒ…å«â€˜iâ€™çš„å•è¯å˜æˆçº¢è‰²ã€‚åªéœ€æ‰“å°ä»£ç ï¼Œä¸è¦è§£é‡Šã€‚*'
- en: '![ChatGPT writing an emacs-lisp function](../Images/f3192ac698b86e02481a384264cf2388.png
    "ChatGPT writing an emacs-lisp function")'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![ChatGPTç¼–å†™ä¸€ä¸ªemacs-lispå‡½æ•°](../Images/f3192ac698b86e02481a384264cf2388.png "ChatGPTç¼–å†™ä¸€ä¸ªemacs-lispå‡½æ•°")'
- en: 'Hereâ€™s the code it spat out, if you canâ€™t read the screenshot:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çœ‹ä¸æ‡‚æˆªå›¾ï¼Œè¿™æ˜¯å®ƒè¾“å‡ºçš„ä»£ç ï¼š
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'I copied this code directly into my Emacs session and ran it, and it did exactly
    what I asked it to do:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç›´æ¥å°†è¿™æ®µä»£ç å¤åˆ¶åˆ°æˆ‘çš„Emacsä¼šè¯ä¸­å¹¶è¿è¡Œäº†å®ƒï¼Œå®ƒç¡®å®åšåˆ°äº†æˆ‘è¦æ±‚çš„äº‹æƒ…ï¼š
- en: '![Running the code in an Emacs session](../Images/849192c327fbe9be2735323583d28e49.png
    "Running the code in an Emacs session")'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![åœ¨Emacsä¼šè¯ä¸­è¿è¡Œä»£ç ](../Images/849192c327fbe9be2735323583d28e49.png "åœ¨Emacsä¼šè¯ä¸­è¿è¡Œä»£ç ")'
- en: As you can see from the screenshot, I ran the command and it opened a buffer,
    printed the requested text, and then turned all the words containing â€˜iâ€™ red.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ ä»æˆªå›¾ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘è¿è¡Œäº†è¿™ä¸ªå‘½ä»¤ï¼Œå®ƒæ‰“å¼€äº†ä¸€ä¸ªç¼“å†²åŒºï¼Œæ‰“å°äº†è¯·æ±‚çš„æ–‡æœ¬ï¼Œç„¶åå°†æ‰€æœ‰åŒ…å«â€˜iâ€™çš„å•è¯å˜æˆäº†çº¢è‰²ã€‚
- en: In one shot, ChatGPT has produced completely working code from a sloppy English
    description! With voice input wired up, I could have written this program by asking
    my computer to do it.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPTä¸€æ¬¡æ€§ä»ä¸€ä¸ªæ‚ä¹±çš„è‹±æ–‡æè¿°ä¸­ç”Ÿæˆäº†å®Œå…¨å¯å·¥ä½œçš„ä»£ç ï¼å¦‚æœæœ‰è¯­éŸ³è¾“å…¥ï¼Œæˆ‘å¯ä»¥é€šè¿‡è¯¢é—®æˆ‘çš„è®¡ç®—æœºæ¥ç¼–å†™è¿™ä¸ªç¨‹åºã€‚
- en: And not only does it work correctly, the code that it wrote is actually pretty
    decent emacs-lisp code. Itâ€™s not *complicated*, sure. But itâ€™s good code.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”å®ƒä¸ä»…èƒ½æ­£ç¡®å·¥ä½œï¼Œå®ƒå†™çš„ä»£ç å®é™…ä¸Šæ˜¯ç›¸å½“ä¸é”™çš„emacs-lispä»£ç ã€‚å½“ç„¶ï¼Œå®ƒä¸æ˜¯*å¤æ‚*çš„ã€‚ä½†å®ƒæ˜¯å¥½ä»£ç ã€‚
- en: Of course people have done much, much fancier things than this. Someone [wrote](https://twitter.com/heykahn/status/1635752848398102530?s=20)
    a product description on a napkin, took a picture, and GPT wrote a working web
    app that implements the product description on the napkin in the picture. The
    amount of power here is honestly unknown; itâ€™s more like a cavern that we havenâ€™t
    fully explored. And it just gets deeper as the LLMs get bigger.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œäººä»¬åšè¿‡æ¯”è¿™æ›´å¤æ‚å¾—å¤šçš„äº‹æƒ…ã€‚æœ‰äººåœ¨é¤å·¾çº¸ä¸Š[å†™ä¸‹](https://twitter.com/heykahn/status/1635752848398102530?s=20)äº†ä¸€ä¸ªäº§å“æè¿°ï¼Œæ‹äº†ç…§ï¼ŒGPTå†™äº†ä¸€ä¸ªå®ç°é¤å·¾çº¸ä¸Šäº§å“æè¿°çš„å·¥ä½œWebåº”ç”¨ç¨‹åºã€‚è¿™é‡Œçš„èƒ½é‡é‡çº§å®åœ¨æ˜¯æœªçŸ¥çš„ï¼›è¿™æ›´åƒæ˜¯ä¸€ä¸ªæˆ‘ä»¬å°šæœªå®Œå…¨æ¢ç´¢çš„æ´ç©´ã€‚éšç€LLMså˜å¾—æ›´å¤§ï¼Œå®ƒåªä¼šå˜å¾—æ›´æ·±ã€‚
- en: I mean, this stuff is *unbelievably* powerful. And yet I am persistently met
    with a mixture of disbelief and pearl-clutching. Argh, the pearl-clutching! Donâ€™t
    even get me started on the pearl-clutching. Oh look, now youâ€™ve got me started.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„æ„æ€æ˜¯ï¼Œè¿™ä¸œè¥¿*æ— æ¯”*å¼ºå¤§ã€‚ç„¶è€Œï¼Œæˆ‘å§‹ç»ˆé‡åˆ°ä¸€ç§æ€€ç–‘å’ŒæƒŠæ…Œçš„æ··åˆä½“ã€‚å•Šï¼Œé‚£æƒŠæ…Œï¼åˆ«è®©æˆ‘å¼€å§‹é‚£ä¸ªã€‚å“¦çœ‹ï¼Œç°åœ¨ä½ è®©æˆ‘å¼€å§‹äº†ã€‚
- en: Okay, you asked for it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œä½ è‡ªæ‰¾çš„ã€‚
- en: '[](#whining-about-trust-issues)Whining about Trust Issues'
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#whining-about-trust-issues)æŠ±æ€¨ä¿¡ä»»é—®é¢˜'
- en: '*<Rant mode fully engaged>*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*<å‘ç‰¢éªšæ¨¡å¼å…¨å¼€>*'
- en: One of the craziest damned things I hear devs say about LLM-based coding help
    is that they canâ€™t â€œtrustâ€ the code that it writes, because it â€œmight have bugs
    in itâ€.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¬åˆ°å¼€å‘äººå‘˜å…³äºåŸºäºLLMçš„ç¼–ç å¸®åŠ©è¯´çš„æœ€ç–¯ç‹‚çš„äº‹æƒ…ä¹‹ä¸€æ˜¯ï¼Œä»–ä»¬ä¸èƒ½â€œä¿¡ä»»â€å®ƒå†™çš„ä»£ç ï¼Œå› ä¸ºå®ƒâ€œå¯èƒ½æœ‰bugâ€ã€‚
- en: Ah me, these crazy crazy devs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å•Šï¼Œè¿™äº›ç–¯ç‹‚çš„å¼€å‘äººå‘˜å•Šã€‚
- en: Can you trust code you yeeted over from Stack Overflow? NO!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ èƒ½ä¿¡ä»»ä½ ä»Stack Overflowä¸ŠæŠ„è¿‡æ¥çš„ä»£ç å—ï¼Ÿä¸ï¼
- en: Can you trust code you copied from somewhere else in your code base? NO!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ èƒ½ç›¸ä¿¡ä»ä»£ç åº“ä¸­å¤åˆ¶çš„ä»£ç å—ï¼Ÿä¸ï¼
- en: Can you trust code you *just now wrote carefully by hand, yourself?* NOOOO!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ èƒ½ä¿¡ä»»ä½ *åˆšåˆšä»”ç»†æ‰‹å†™çš„ä»£ç å—ï¼Ÿ* ä¸ï¼
- en: All you crazy MFs are completely overlooking the fact that **software engineering
    exists as a discipline because you cannot EVER under any circumstances TRUST CODE.**
    Thatâ€™s why we have *reviewers*. And *linters*. And *debuggers*. And *unit tests*.
    And *integration tests*. And *staging environments*. And *runbooks*. And all of
    goddamned *Operational Excellence*. And *security checkers*, and *compliance scanners*,
    and on, and on and on!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä»¬è¿™äº›ç–¯ç‹‚çš„å®¶ä¼™å®Œå…¨å¿½è§†äº†ä¸€ä¸ªäº‹å®ï¼Œ**è½¯ä»¶å·¥ç¨‹å­˜åœ¨æ˜¯å› ä¸ºä½ æ°¸è¿œä¸èƒ½åœ¨ä»»ä½•æƒ…å†µä¸‹ä¿¡ä»»ä»£ç ã€‚** è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬æœ‰*å®¡æŸ¥è€…*ã€‚è¿˜æœ‰*linters*ã€‚å’Œ*debuggers*ã€‚å’Œ*unit
    tests*ã€‚å’Œ*integration tests*ã€‚å’Œ*staging environments*ã€‚å’Œ*runbooks*ã€‚ä»¥åŠæ‰€æœ‰è¯¥æ­»çš„*è¿ç»´å“è¶Š*ã€‚è¿˜æœ‰*å®‰å…¨æ£€æŸ¥å™¨*ï¼Œå’Œ*åˆè§„æ‰«æå™¨*ï¼Œç­‰ç­‰ç­‰ç­‰ï¼
- en: 'So the next one of you to complain that â€œyou canâ€™t trust LLM codeâ€ gets a little
    badge that says â€œWelcome to *engineering* motherfuckerâ€. Youâ€™ve finally learned
    the secret of the trade: Donâ€™t. Trust. Anything!'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œä¸‹ä¸€ä¸ªæŠ±æ€¨â€œä½ ä¸èƒ½ä¿¡ä»»LLMä»£ç â€çš„äººå°†å¾—åˆ°ä¸€ä¸ªå°å¾½ç« ï¼Œä¸Šé¢å†™ç€â€œæ¬¢è¿æ¥åˆ°*å·¥ç¨‹*ï¼Œæ··è›‹â€ã€‚ä½ ç»ˆäºå­¦ä¼šäº†è¿™ä¸ªè¡Œä¸šçš„ç§˜å¯†ï¼šä¸ã€‚ä¿¡ã€‚ä»»ã€‚ä»»ä½•ä¸œè¥¿ï¼
- en: Peeps, letâ€™s do some really simple back-of-envelope math. Trust me, it wonâ€™t
    be difficult math.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‹å‹ä»¬ï¼Œè®©æˆ‘ä»¬åšä¸€äº›éå¸¸ç®€å•çš„è‰ç¨¿æ•°å­¦ã€‚ç›¸ä¿¡æˆ‘ï¼Œè¿™ä¸ä¼šæ˜¯å›°éš¾çš„æ•°å­¦ã€‚
- en: You get the LLM to draft some code for you thatâ€™s 80% complete/correct.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è®©LLMä¸ºä½ èµ·è‰ä¸€äº›å®Œæˆ/æ­£ç¡®åº¦è¾¾åˆ°80%çš„ä»£ç ã€‚
- en: You tweak the last 20% by hand.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ‰‹åŠ¨è°ƒæ•´æœ€åçš„20%ã€‚
- en: How much of a productivity increase is that? Well jeepers, if youâ€™re only doing
    1/5th the work, then you areâ€¦ *punches buttons on calculator watch*â€¦ **five times
    as productive.** ğŸ˜²
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†å¸¦æ¥å¤šå°‘ç”Ÿäº§åŠ›æå‡ï¼Ÿå“‡å“¦ï¼Œå¦‚æœä½ åªåšäº†äº”åˆ†ä¹‹ä¸€çš„å·¥ä½œï¼Œé‚£ä¹ˆä½ å°±æ˜¯â€¦ *åœ¨è®¡ç®—æ‰‹è¡¨ä¸ŠæŒ‰ä¸‹æŒ‰é’®*â€¦ **ç”Ÿäº§åŠ›æé«˜äº”å€**ã€‚ğŸ˜²
- en: When was the last time you got a 5x productivity boost from *anything* that
    didnâ€™t involve some sort of chemicals?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šæ¬¡ä½ ä»*ä»»ä½•*äº‹æƒ…ä¸­è·å¾—5å€ç”Ÿäº§åŠ›æå‡æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿé‚£ä¸æ¶‰åŠæŸç§åŒ–å­¦ç‰©è´¨ï¼Ÿ
- en: Iâ€™m serious. I just donâ€™t get people. How can you not appreciate the *historic*
    change happening right now?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯è®¤çœŸçš„ã€‚æˆ‘å°±æ˜¯ä¸æ˜ç™½äººä»¬ã€‚ä½ æ€ä¹ˆèƒ½ä¸æ¬£èµç°åœ¨æ­£åœ¨å‘ç”Ÿçš„*å†å²æ€§*å˜åŒ–å‘¢ï¼Ÿ
- en: OK time to get concrete. Iâ€™m already on page 7, and my last attempt at this
    blog ran 25+ pages and languished for weeks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½äº†ï¼Œæ˜¯æ—¶å€™å…·ä½“ä¸€ç‚¹äº†ã€‚æˆ‘å·²ç»åœ¨ç¬¬7é¡µäº†ï¼Œè€Œæˆ‘ä¸Šæ¬¡å°è¯•å†™è¿™ç¯‡åšå®¢æ—¶è¶…è¿‡25é¡µï¼Œè¿˜è’åºŸäº†å‡ å‘¨ã€‚
- en: Letâ€™s finish this.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»“æŸè¿™ä¸ªã€‚
- en: '*<Rant mode disengaged... but lurking>*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*<å‘ç‰¢éªšæ¨¡å¼å·²è§£é™¤...ä½†æ½œä¼ç€>*ã€‚'
- en: '[](#a-brief-mini-history-of-llms)A Brief Mini-History of LLMs'
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#a-brief-mini-history-of-llms)LLMçš„ç®€è¦å°å†å²'
- en: OK soooooâ€¦ this is the part that went on for 20 pages before, so letâ€™s just
    make it reeeeeal simple. One paragraph.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½äº†ï¼Œæ‰€ä»¥â€¦â€¦è¿™æ˜¯ä¹‹å‰å†™äº†20é¡µçš„éƒ¨åˆ†ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ç®€åŒ–ä¸€ä¸‹ã€‚ä¸€æ®µè¯ã€‚
- en: 'Here is everything you need to know about the history of LLMs, for our purposes
    today:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä½ ä»Šå¤©éœ€è¦äº†è§£çš„LLMå†å²çš„ä¸€åˆ‡ï¼š
- en: '| ![A transformer diagram](../Images/3c333fb988af676ed868461757fa75b9.png "A
    transformer diagram") |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| ![ä¸€ä¸ªå˜å‹å™¨å›¾è¡¨](../Images/3c333fb988af676ed868461757fa75b9.png "ä¸€ä¸ªå˜å‹å™¨å›¾è¡¨") |'
- en: The Google Brain team published a paper in 2017 called [Attention is All You
    Need](https://arxiv.org/abs/1706.03762).
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è°·æ­ŒBrainå›¢é˜Ÿåœ¨2017å¹´å‘è¡¨äº†ä¸€ç¯‡åä¸º[Attention is All You Need](https://arxiv.org/abs/1706.03762)çš„è®ºæ–‡ã€‚
- en: It introduced the now-famous Transformer architecture that you see to the left.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒä»‹ç»äº†ä½ åœ¨å·¦è¾¹çœ‹åˆ°çš„ç°åœ¨è‘—åçš„Transformeræ¶æ„ã€‚
- en: Everyone uses this now. It replaced *~everything* in AI.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¯ä¸ªäººéƒ½åœ¨ä½¿ç”¨è¿™ä¸ªã€‚å®ƒå–ä»£äº†*å‡ ä¹æ‰€æœ‰*çš„AIã€‚
- en: Google did absolutely nothing with this invention, opting for violent knee-jerking
    later, as per their usual M.O.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è°·æ­Œå¯¹è¿™ä¸€å‘æ˜å®Œå…¨æ²¡æœ‰åšä»»ä½•äº‹æƒ…ï¼Œé€‰æ‹©ä¹‹åè¿›è¡Œæš´åŠ›æ€§çš„ååº”ï¼Œè¿™æ˜¯ä»–ä»¬é€šå¸¸çš„ä½œæ³•ã€‚
- en: Meanwhile, others started training massive Transformers on obscene amounts of
    data. They began calling them Large Language Models (LLMs).
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸æ­¤åŒæ—¶ï¼Œå…¶ä»–äººå¼€å§‹åœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒåºå¤§çš„Transformerã€‚ä»–ä»¬å¼€å§‹ç§°ä¹‹ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚
- en: OpenAI came along with ChatGPT on November 30th 2022, the first LLM-based chatbot,
    missing out on an obvious opportunity to call it Large Marge. Why did they not
    do this.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAIåœ¨2022å¹´11æœˆ30æ—¥æ¨å‡ºäº†ChatGPTï¼Œç¬¬ä¸€ä¸ªåŸºäºLLMçš„èŠå¤©æœºå™¨äººï¼Œé”™è¿‡äº†ä¸€ä¸ªæ˜æ˜¾çš„æœºä¼šï¼Œæ²¡æœ‰å°†å…¶å‘½åä¸ºLarge Margeã€‚ä¸ºä»€ä¹ˆä»–ä»¬æ²¡æœ‰è¿™æ ·åšã€‚
- en: Ever since then has been **full batshit insanity**, with new LLM-based products
    launching daily and technical advances happening every few hours. Itâ€™s *impossible*
    to track it all.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»é‚£æ—¶èµ·ï¼Œ**ä¸€åˆ‡éƒ½å˜å¾—ç–¯ç‹‚æ— æ¯”**ï¼Œæ¯å¤©éƒ½æœ‰åŸºäºLLMçš„æ–°äº§å“æ¨å‡ºï¼ŒæŠ€æœ¯è¿›æ­¥æ¯éš”å‡ ä¸ªå°æ—¶å°±ä¼šå‘ç”Ÿã€‚è¦è¿½è¸ªè¿™ä¸€åˆ‡*å‡ ä¹æ˜¯ä¸å¯èƒ½çš„*ã€‚
- en: 'Money Volcano Alert: First lava flecks detected.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡‘é’±ç«å±±è­¦æŠ¥ï¼šé¦–æ¬¡æ£€æµ‹åˆ°ç†”å²©é£æº…ã€‚
- en: '|'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Congrats, youâ€™re all caught up on the history of LLMs. Go watch [this amazing
    video](https://www.youtube.com/watch?v=kCc8FmEb1nY) for how to implement it in
    Python.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œï¼Œä½ å·²ç»äº†è§£äº†LLMçš„å†å²ã€‚å»è§‚çœ‹[è¿™ä¸ªæƒŠäººçš„è§†é¢‘](https://www.youtube.com/watch?v=kCc8FmEb1nY)äº†è§£å¦‚ä½•åœ¨Pythonä¸­å®ç°å®ƒã€‚
- en: '[](#a-brief-introduction-to-coding-assistants)A brief introduction to Coding
    Assistants'
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#a-brief-introduction-to-coding-assistants)ç¼–ç åŠ©æ‰‹ç®€ä»‹'
- en: OK now we can talk coding assistants. Theyâ€™re just a thing that sits in your
    IDE and they talk to the LLM for you.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥è°ˆè®ºç¼–ç åŠ©æ‰‹äº†ã€‚å®ƒä»¬åªæ˜¯ååœ¨ä½ çš„IDEä¸­ä¸LLMäº¤è°ˆçš„ä¸œè¥¿ã€‚
- en: Depending on the particular assistant, they can read and explain code, document
    code, write code, autocomplete it, diagnose issues, and even perform arbitrary
    IDE tasks through â€œagentsâ€ that give the LLM robotic powers, including the ability
    to wield and target laser guns, if someone wants to put in the work. Some assistants
    also understand your project environment and can answer questions about build
    targets, branches, your IDE, etc.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ç‰¹å®šåŠ©æ‰‹çš„ä¸åŒï¼Œå®ƒä»¬å¯ä»¥é˜…è¯»å’Œè§£é‡Šä»£ç ï¼Œæ–‡æ¡£åŒ–ä»£ç ï¼Œç¼–å†™ä»£ç ï¼Œè‡ªåŠ¨è¡¥å…¨ä»£ç ï¼Œè¯Šæ–­é—®é¢˜ï¼Œç”šè‡³é€šè¿‡ç»™äºˆLLMæœºå™¨äººèƒ½åŠ›çš„â€œä»£ç†â€æ‰§è¡Œä»»æ„IDEä»»åŠ¡ï¼ŒåŒ…æ‹¬ä½¿ç”¨å’Œç„å‡†æ¿€å…‰æªï¼Œå¦‚æœæœ‰äººæ„¿æ„ä»˜å‡ºåŠªåŠ›ã€‚ä¸€äº›åŠ©æ‰‹è¿˜äº†è§£æ‚¨çš„é¡¹ç›®ç¯å¢ƒï¼Œå¹¶å¯ä»¥å›ç­”å…³äºæ„å»ºç›®æ ‡ã€åˆ†æ”¯ã€æ‚¨çš„IDEç­‰çš„é—®é¢˜ã€‚
- en: So, already pretty cool. Right?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œå·²ç»ç›¸å½“é…·äº†ã€‚å¯¹å§ï¼Ÿ
- en: But now they are beginning to be able to perform more complex tasks, such as
    generating a PR from the diffs on the current branch, including a detailed commit
    message summarizing the changes.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç°åœ¨å®ƒä»¬å¼€å§‹èƒ½å¤Ÿæ‰§è¡Œæ›´å¤æ‚çš„ä»»åŠ¡ï¼Œæ¯”å¦‚ä»å½“å‰åˆ†æ”¯çš„å·®å¼‚ä¸­ç”Ÿæˆä¸€ä¸ªPRï¼ŒåŒ…æ‹¬æ€»ç»“æ›´æ”¹çš„è¯¦ç»†æäº¤æ¶ˆæ¯ã€‚
- en: Some assistants have a conversational/chat interface, too. This kind can do
    everything a bot like ChatGPT can do, like drafting emails, or answering random
    questions about the code base or the environment.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›åŠ©æ‰‹è¿˜æœ‰å¯¹è¯/èŠå¤©ç•Œé¢ã€‚è¿™ç§ç±»å‹å¯ä»¥åšChatGPTè¿™æ ·çš„æœºå™¨äººå¯ä»¥åšçš„ä¸€åˆ‡ï¼Œæ¯”å¦‚èµ·è‰ç”µå­é‚®ä»¶ï¼Œæˆ–å›ç­”å…³äºä»£ç åº“æˆ–ç¯å¢ƒçš„éšæœºé—®é¢˜ã€‚
- en: I personally prefer a coding assistant with a chat interface. In part because
    I can type, but also because it makes them a platform. I can build my own workflows.
    Bonus points if they expose the underlying platform bits with APIs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ªäººæ›´å–œæ¬¢å¸¦æœ‰èŠå¤©ç•Œé¢çš„ç¼–ç åŠ©æ‰‹ã€‚éƒ¨åˆ†åŸå› æ˜¯å› ä¸ºæˆ‘å¯ä»¥æ‰“å­—ï¼Œä½†ä¹Ÿå› ä¸ºå®ƒä½¿å®ƒä»¬æˆä¸ºä¸€ä¸ªå¹³å°ã€‚æˆ‘å¯ä»¥æ„å»ºè‡ªå·±çš„å·¥ä½œæµç¨‹ã€‚å¦‚æœå®ƒä»¬é€šè¿‡APIæš´éœ²åº•å±‚å¹³å°éƒ¨åˆ†ï¼Œé‚£å°±æ›´åŠ åˆ†ã€‚
- en: I guess the simplest way to think about it would be a sort of â€œreal-time in-IDE
    Stack Overflowâ€ coupled with a really powerful new set of boilerplate automation
    tasks.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³æœ€ç®€å•çš„æ€è€ƒæ–¹å¼å¯èƒ½æ˜¯ä¸€ç§â€œå®æ—¶IDEä¸­çš„Stack Overflowâ€ï¼Œå†åŠ ä¸Šä¸€ä¸ªéå¸¸å¼ºå¤§çš„æ–°çš„æ¨¡æ¿è‡ªåŠ¨åŒ–ä»»åŠ¡é›†ã€‚
- en: OK, congrats again â€“ youâ€™re up to speed on what LLM-based coding assistants
    can do. Itâ€™sâ€¦ pretty much anything. You could hook it up to outbound email and
    tell it to sell itself. Skyâ€™s the limit. At this point weâ€™re more limited by imagination
    than by technology.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œå†æ¬¡æ­å–œ - ä½ å·²ç»äº†è§£äº†åŸºäºLLMçš„ç¼–ç åŠ©æ‰‹å¯ä»¥åšä»€ä¹ˆã€‚å®ƒ...å‡ ä¹å¯ä»¥åšä»»ä½•äº‹æƒ…ã€‚ä½ å¯ä»¥å°†å…¶è¿æ¥åˆ°å¤–å‘é‚®ä»¶ï¼Œå¹¶å‘Šè¯‰å®ƒè‡ªæˆ‘æ¨é”€ã€‚å¤©ç©ºæ˜¯æé™ã€‚åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬æ›´å¤šåœ°å—åˆ°æƒ³è±¡åŠ›çš„é™åˆ¶ï¼Œè€Œä¸æ˜¯æŠ€æœ¯çš„é™åˆ¶ã€‚
- en: So! Yeah. Coding assistants. I hope by now you get how powerful theyâ€™re going
    to be. They may take different shapes and forms, but theyâ€™re all going to be incredibly
    badass before very much longer.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼æ˜¯çš„ã€‚ç¼–ç åŠ©æ‰‹ã€‚æˆ‘å¸Œæœ›åˆ°ç°åœ¨ä½ æ˜ç™½å®ƒä»¬å°†ä¼šæœ‰å¤šä¹ˆå¼ºå¤§ã€‚å®ƒä»¬å¯èƒ½ä¼šé‡‡å–ä¸åŒçš„å½¢å¼ï¼Œä½†å®ƒä»¬åœ¨ä¸ä¹…çš„å°†æ¥éƒ½å°†å˜å¾—éå¸¸å‰å®³ã€‚
- en: Letâ€™s dig a little into how they understand your personal code, and then weâ€™re
    ready to party. ğŸ‰
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç¨å¾®æ·±å…¥äº†è§£å®ƒä»¬å¦‚ä½•ç†è§£ä½ çš„ä¸ªäººä»£ç ï¼Œç„¶åæˆ‘ä»¬å°±å‡†å¤‡å¥½å¼€å§‹æ´¾å¯¹äº†ã€‚ğŸ‰
- en: '[](#trainingfine-tuning-vs-search)Training/fine-tuning vs Search'
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#trainingfine-tuning-vs-search)è®­ç»ƒ/å¾®è°ƒ vs æœç´¢'
- en: LLMs are trained on an absolutely staggering amount of dataâ€¦ but that doesnâ€™t
    include your code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: LLMsæ˜¯åœ¨ç»å¯¹æƒŠäººæ•°é‡çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒçš„...ä½†è¿™å¹¶ä¸åŒ…æ‹¬ä½ çš„ä»£ç ã€‚
- en: There are two basic approaches to making the LLM smarter about your code. The
    first is to fine-tune (or train) on your code. This is not a business model that
    has been fully fleshed out yet, but itâ€™s coming. And importantly itâ€™s only part
    of the picture.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸¤ç§åŸºæœ¬æ–¹æ³•å¯ä»¥ä½¿LLMæ›´åŠ äº†è§£ä½ çš„ä»£ç ã€‚ç¬¬ä¸€ç§æ˜¯åœ¨ä½ çš„ä»£ç ä¸Šè¿›è¡Œå¾®è°ƒï¼ˆæˆ–è®­ç»ƒï¼‰ã€‚è¿™è¿˜ä¸æ˜¯ä¸€ä¸ªå®Œå…¨å®Œå–„çš„å•†ä¸šæ¨¡å¼ï¼Œä½†å®ƒæ­£åœ¨å‘å±•ã€‚è€Œä¸”é‡è¦çš„æ˜¯è¿™åªæ˜¯é—®é¢˜çš„ä¸€éƒ¨åˆ†ã€‚
- en: 'The other way is to bring in a search engine. You can think of it as three
    related scenarios:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§æ–¹æ³•æ˜¯å¼•å…¥ä¸€ä¸ªæœç´¢å¼•æ“ã€‚ä½ å¯ä»¥å°†å…¶è§†ä¸ºä¸‰ç§ç›¸å…³çš„åœºæ™¯ï¼š
- en: A raw LLM is like a Harvard CS grad who knows a lot about coding and took a
    magic mushroom about 4 hours ago, so itâ€™s mostly worn off, but not totally.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªåŸå§‹çš„LLMå°±åƒæ˜¯ä¸€ä¸ªå“ˆä½›è®¡ç®—æœºç§‘å­¦æ¯•ä¸šç”Ÿï¼Œå¯¹ç¼–ç æœ‰å¾ˆå¤šäº†è§£ï¼Œå¹¶ä¸”å¤§çº¦4å°æ—¶å‰åƒäº†ä¸€é¢—é­”æ³•è˜‘è‡ï¼Œæ‰€ä»¥æ•ˆæœå¤§éƒ¨åˆ†å·²ç»æ¶ˆé€€ï¼Œä½†è¿˜æ²¡æœ‰å®Œå…¨æ¶ˆå¤±ã€‚
- en: Fine-tuning it on your code base is like having it study your code carefully,
    which means it will give better answers in general.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ä½ çš„ä»£ç åº“ä¸Šå¯¹å…¶è¿›è¡Œå¾®è°ƒå°±åƒæ˜¯è®©å®ƒä»”ç»†ç ”ç©¶ä½ çš„ä»£ç ï¼Œè¿™æ„å‘³ç€å®ƒé€šå¸¸ä¼šç»™å‡ºæ›´å¥½çš„ç­”æ¡ˆã€‚
- en: Incorporating a search engine, much like for humans, makes the AI even more
    effective, because it can answer direct queries very quickly. And importantly,
    because the search engine can be used to populate the query context.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ å…¥ä¸€ä¸ªæœç´¢å¼•æ“ï¼Œå°±åƒå¯¹äººç±»æ¥è¯´ä¸€æ ·ï¼Œä½¿å¾—AIæ›´åŠ æœ‰æ•ˆï¼Œå› ä¸ºå®ƒå¯ä»¥éå¸¸å¿«é€Ÿåœ°å›ç­”ç›´æ¥çš„æŸ¥è¯¢ã€‚è€Œä¸”é‡è¦çš„æ˜¯ï¼Œå› ä¸ºæœç´¢å¼•æ“å¯ä»¥ç”¨æ¥å¡«å……æŸ¥è¯¢ä¸Šä¸‹æ–‡ã€‚
- en: Meaning, a search engine can be useful twice per query â€“ once when figuring
    out how to *describe* and *contextualize* the query, and again potentially when
    answering the query.
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„æ€æ˜¯ï¼Œä¸€ä¸ªæœç´¢å¼•æ“åœ¨æ¯æ¬¡æŸ¥è¯¢ä¸­å¯ä»¥æœ‰ä¸¤æ¬¡æœ‰ç”¨ - ä¸€æ¬¡æ˜¯åœ¨ç¡®å®šå¦‚ä½•*æè¿°*å’Œ*ä¸Šä¸‹æ–‡åŒ–*æŸ¥è¯¢æ—¶ï¼Œå¦ä¸€æ¬¡æ˜¯åœ¨å›ç­”æŸ¥è¯¢æ—¶ã€‚
- en: You talk to LLMs by sending them an action or query, plus some relevant context.
    So for instance, if you want it to write a unit test for a function, then you
    need to pass along that whole function, along with any other relevant code (e.g.
    test-fixture code) so that it gets the test right.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ é€šè¿‡å‘é€ä¸€ä¸ªåŠ¨ä½œæˆ–æŸ¥è¯¢ä»¥åŠä¸€äº›ç›¸å…³ä¸Šä¸‹æ–‡æ¥ä¸LLMsäº¤æµã€‚æ‰€ä»¥ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³è®©å®ƒä¸ºä¸€ä¸ªå‡½æ•°ç¼–å†™ä¸€ä¸ªå•å…ƒæµ‹è¯•ï¼Œé‚£ä¹ˆä½ éœ€è¦ä¼ é€’æ•´ä¸ªå‡½æ•°ï¼Œä»¥åŠä»»ä½•å…¶ä»–ç›¸å…³ä»£ç ï¼ˆä¾‹å¦‚æµ‹è¯•å¤¹å…·ä»£ç ï¼‰ï¼Œä»¥ä¾¿å®ƒæ­£ç¡®åœ°è¿›è¡Œæµ‹è¯•ã€‚
- en: That context you send over is called the **context window**, and I think of
    it as the â€œcheat sheetâ€ of information that you pass along as part of your query.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å‘é€çš„ä¸Šä¸‹æ–‡è¢«ç§°ä¸º**ä¸Šä¸‹æ–‡çª—å£**ï¼Œæˆ‘æŠŠå®ƒçœ‹ä½œæ˜¯ä½ åœ¨æŸ¥è¯¢ä¸­ä¼ é€’çš„â€œä½œå¼Šçº¸â€ä¿¡æ¯ã€‚
- en: And folks, it ainâ€™t much. Itâ€™s almost exactly like a 2-sided index card vs your
    whole textbook, for an exam. They give you between 4k and 32k tokens of 3-4 characters
    each, so at best, maybe 100k of text, to input into the LLM as context for your
    query. That 100k cheat sheet is how you tell the LLM about ***your*** code.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‹å‹ä»¬ï¼Œè¿™å¹¶ä¸å¤šã€‚è¿™å‡ ä¹ä¸ä½ æ•´æœ¬æ•™ç§‘ä¹¦ç›¸æ¯”å°±åƒæ˜¯ä¸€ä¸ªåŒé¢ç´¢å¼•å¡ï¼Œç”¨äºè€ƒè¯•ã€‚ä»–ä»¬ç»™ä½ 4kåˆ°32kä¸ª3-4ä¸ªå­—ç¬¦çš„ä»¤ç‰Œï¼Œå› æ­¤æœ€å¥½çš„æƒ…å†µä¸‹ï¼Œå¯èƒ½æœ‰100kçš„æ–‡æœ¬ï¼Œç”¨äºè¾“å…¥LLMä½œä¸ºæŸ¥è¯¢ä¸Šä¸‹æ–‡ã€‚é‚£100kçš„å°æŠ„å°±æ˜¯ä½ å‘Šè¯‰LLMå…³äº***ä½ çš„***ä»£ç çš„æ–¹å¼ã€‚
- en: 'In an ideal world, youâ€™d just pass your entire code base in with each query.
    In fact, Jay Hack just [tweeted](https://twitter.com/mathemagic1an/status/1636121914849792000?s=20)
    a graph showing how the latest context window size in GPT-4 compares to some popular
    code bases:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç†æƒ³çš„æƒ…å†µä¸‹ï¼Œä½ åº”è¯¥åœ¨æ¯æ¬¡æŸ¥è¯¢ä¸­ä¼ é€’æ•´ä¸ªä»£ç åº“ã€‚äº‹å®ä¸Šï¼ŒJay Hackåˆšåˆšåœ¨æ¨ç‰¹ä¸Š[å‘æ¨æ–‡](https://twitter.com/mathemagic1an/status/1636121914849792000?s=20)å±•ç¤ºäº†æœ€æ–°GPT-4ä¸Šä¸‹æ–‡çª—å£å¤§å°ä¸ä¸€äº›æµè¡Œä»£ç åº“çš„æ¯”è¾ƒï¼š
- en: '![Diagram of GPT-4 context window versus code base sizes](../Images/f617df096c2e9bcf4ccddff9c25feb77.png
    "Diagram of GPT-4 context window versus code base sizes")'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![GPT-4ä¸Šä¸‹æ–‡çª—å£ä¸ä»£ç åº“å¤§å°çš„å›¾è¡¨](../Images/f617df096c2e9bcf4ccddff9c25feb77.png "GPT-4ä¸Šä¸‹æ–‡çª—å£ä¸ä»£ç åº“å¤§å°çš„å›¾è¡¨")'
- en: Which is kind of excitingâ€¦ until you realize that itâ€™s still just incredibly
    tiny compared to real-world code bases. Itâ€™s an index card vs a textbookâ€¦ just
    a slightly bigger index card.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ‰ç‚¹ä»¤äººå…´å¥‹... ç›´åˆ°ä½ æ„è¯†åˆ°ä¸çœŸå®ä»£ç åº“ç›¸æ¯”ï¼Œå®ƒä»ç„¶å¾®ä¸è¶³é“ã€‚è¿™å°±åƒä¸€ä¸ªç´¢å¼•å¡å¯¹æ¯”ä¸€æœ¬æ•™ç§‘ä¹¦... åªæ˜¯ä¸€ä¸ªç•¥å¤§ä¸€ç‚¹çš„ç´¢å¼•å¡ã€‚
- en: That cheat sheet is all you get. Thatâ€™s how you talk to an LLM. You pass it
    a cheat sheet.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£å¼ å°æŠ„å°±æ˜¯ä½ å¾—åˆ°çš„ä¸€åˆ‡ã€‚è¿™å°±æ˜¯ä½ ä¸LLMäº¤æµçš„æ–¹å¼ã€‚ä½ ç»™å®ƒä¸€å¼ å°æŠ„ã€‚
- en: Which means what goes ON that cheat sheet, as you can probably imagine, is **really
    really important.**
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æ”¾åœ¨è¿™å¼ å°æŠ„ä¸Šçš„å†…å®¹ï¼Œæ­£å¦‚ä½ å¯èƒ½æƒ³è±¡çš„é‚£æ ·ï¼Œæ˜¯**éå¸¸é‡è¦çš„**ã€‚
- en: And with that, friends, we are finally ready for the punchline, the party, and
    the demo.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†è¿™ä¸€ç‚¹ï¼Œæœ‹å‹ä»¬ï¼Œæˆ‘ä»¬ç»ˆäºå‡†å¤‡å¥½äº†ç»“å°¾ï¼Œæ´¾å¯¹å’Œæ¼”ç¤ºã€‚
- en: You made it!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æˆåŠŸäº†ï¼
- en: '[](#cheating-is-all-you-need)Cheating is All You Need'
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#cheating-is-all-you-need)æ¬ºéª—å°±æ˜¯ä½ æ‰€éœ€è¦çš„'
- en: 'There are, by my last count, approximately 13 hillion frillion jillion LLM-backed
    coding assistants out there, as of mid-March. But they are all in a desperate
    race to the bottom, because theyâ€™re all using the exact same raw materials: An
    LLM, your IDE, your code base, and that pesky little context window.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ®æˆ‘ä¸Šæ¬¡ç»Ÿè®¡ï¼Œæˆªè‡³ä¸‰æœˆä¸­æ—¬ï¼Œå¤§çº¦æœ‰13 hillion frillion jillionä¸ªç”±LLMæ”¯æŒçš„ç¼–ç åŠ©æ‰‹ã€‚ä½†å®ƒä»¬éƒ½åœ¨ç»æœ›åœ°äº‰å…ˆæåï¼Œå› ä¸ºå®ƒä»¬éƒ½ä½¿ç”¨å®Œå…¨ç›¸åŒçš„åŸææ–™ï¼šä¸€ä¸ªLLMï¼Œä½ çš„IDEï¼Œä½ çš„ä»£ç åº“ï¼Œä»¥åŠé‚£ä¸ªè®¨åŒçš„å°ä¸Šä¸‹æ–‡çª—å£ã€‚
- en: Nobody can differentiate on the LLM; theyâ€™re all about the same. And the IDE
    and your code base are the same. All they can try to differentiate on is their
    UI and workflows, which theyâ€™re all going to copy off each other. Good for you,
    bad for them.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰äººèƒ½åœ¨LLMä¸ŠåŒºåˆ†è‡ªå·±ï¼›å®ƒä»¬éƒ½å·®ä¸å¤šã€‚IDEå’Œä½ çš„ä»£ç åº“ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚ä»–ä»¬å”¯ä¸€å¯ä»¥å°è¯•åŒºåˆ†çš„æ˜¯ä»–ä»¬çš„UIå’Œå·¥ä½œæµç¨‹ï¼Œè€Œä»–ä»¬éƒ½ä¼šäº’ç›¸æŠ„è¢­ã€‚å¯¹ä½ æœ‰åˆ©ï¼Œå¯¹ä»–ä»¬ä¸åˆ©ã€‚
- en: The punchline, and itâ€™s honestly one of the hardest things to explain, so Iâ€™m
    going the faith-based route today, is that **all the winners in the AI space will
    have data moats.**
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“å°¾ï¼Œè¯´å®è¯ï¼Œè¿™æ˜¯æœ€éš¾è§£é‡Šçš„äº‹æƒ…ä¹‹ä¸€ï¼Œæ‰€ä»¥ä»Šå¤©æˆ‘é€‰æ‹©ä¿¡ä»°ä¹‹è·¯ï¼Œå°±æ˜¯**åœ¨AIé¢†åŸŸï¼Œæ‰€æœ‰çš„èµ¢å®¶éƒ½å°†æ‹¥æœ‰æ•°æ®æŠ¤åŸæ²³ã€‚**
- en: A â€œdata moatâ€ is, in a nutshell, having access to some data that others do not
    have access to.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: â€œæ•°æ®æŠ¤åŸæ²³â€ç®€è€Œè¨€ä¹‹ï¼Œå°±æ˜¯æ‹¥æœ‰ä¸€äº›å…¶ä»–äººæ— æ³•è®¿é—®çš„æ•°æ®ã€‚
- en: You need a data moat to differentiate yourself in the LLM world.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨LLMä¸–ç•Œä¸­ï¼Œä½ éœ€è¦ä¸€ä¸ªæ•°æ®æŠ¤åŸæ²³æ¥åŒºåˆ†è‡ªå·±ã€‚
- en: Why? **Because the data moat is how you populate the context window (â€œcheat
    sheetâ€).**
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆï¼Ÿ**å› ä¸ºæ•°æ®æŠ¤åŸæ²³æ˜¯å¦‚ä½•å¡«å……ä¸Šä¸‹æ–‡çª—å£ï¼ˆâ€œå°æŠ„â€ï¼‰çš„ã€‚**
- en: If you canâ€™t feed the LLM your whole code base, and you can only show it 100k
    characters at a time, then youâ€™d better be *really goddamn good* at fetching the
    right data to stuff into that 100k-char window. Because thatâ€™s the only way to
    affect the quality of the LLMâ€™s output!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ— æ³•å°†æ•´ä¸ªä»£ç åº“è¾“å…¥LLMï¼Œè€Œåªèƒ½æ¯æ¬¡æ˜¾ç¤º100kä¸ªå­—ç¬¦ï¼Œé‚£ä¹ˆä½ æœ€å¥½*éå¸¸éå¸¸æ“…é•¿*è·å–æ­£ç¡®çš„æ•°æ®å¡«å……åˆ°é‚£100kå­—ç¬¦çª—å£ä¸­ã€‚å› ä¸ºè¿™æ˜¯å½±å“LLMè¾“å‡ºè´¨é‡çš„å”¯ä¸€æ–¹æ³•ï¼
- en: Put another way, you need a *sidecar database*. The data moat needs to be fast
    and queryable. This is a Search Problem!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œä½ éœ€è¦ä¸€ä¸ª*è¾…åŠ©æ•°æ®åº“*ã€‚æ•°æ®æŠ¤åŸæ²³éœ€è¦å¿«é€Ÿä¸”å¯æŸ¥è¯¢ã€‚è¿™æ˜¯ä¸€ä¸ªæœç´¢é—®é¢˜ï¼
- en: This is true even outside the world of engineering. There are probably 13 hillion
    jillion killion LLM-based outbound sales products being built like right now,
    as youâ€™re reading this. But only Salesforce and a few other companies with big
    data moats are going to be able to differentiate in that space.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿åœ¨å·¥ç¨‹é¢†åŸŸä¹‹å¤–ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å¯èƒ½æ­£å¦‚ä½ é˜…è¯»è¿™ç¯‡æ–‡ç« æ—¶ï¼Œå¯èƒ½æœ‰13 hillion jillion killionåŸºäºLLMçš„å¤–å‘é”€å”®äº§å“æ­£åœ¨è¢«å»ºç«‹ã€‚ä½†åªæœ‰Salesforceå’Œå…¶ä»–å‡ å®¶æ‹¥æœ‰å¤§æ•°æ®æŠ¤åŸæ²³çš„å…¬å¸æ‰èƒ½åœ¨è¿™ä¸ªé¢†åŸŸä¸­è„±é¢–è€Œå‡ºã€‚
- en: '[](#party-time)Party Time'
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#party-time)æ´¾å¯¹æ—¶é—´'
- en: OK! Youâ€™re finally done learning stuff. Iâ€™m very proud that youâ€™ve made it to
    the end.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½äº†ï¼ä½ ç»ˆäºå­¦å®Œäº†ã€‚æˆ‘ä¸ºä½ èƒ½åšæŒåˆ°æœ€åæ„Ÿåˆ°éå¸¸è‡ªè±ªã€‚
- en: The rest is a private Sourcegraph party. I mean, you can come along if you like,
    because youâ€™re a friend. Iâ€™ll slip you by the door guy.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä½™çš„æ˜¯ç§äººSourcegraphæ´¾å¯¹ã€‚æˆ‘çš„æ„æ€æ˜¯ï¼Œå¦‚æœä½ æ„¿æ„ï¼Œä½ å¯ä»¥ä¸€èµ·æ¥ï¼Œå› ä¸ºä½ æ˜¯æœ‹å‹ã€‚æˆ‘ä¼šè®©ä½ ç»•è¿‡é—¨å£çš„ä¿å®‰ã€‚
- en: Youâ€™ve just graduated from Steveyâ€™s LLM Mini-U, and you have all the necessary
    theoretical background to appreciate why I feel I am the luckiest damn person
    on Earth, and why Iâ€™m throwing a party, right here on page two thousand eight
    hundred and ninety six of this blog post.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åˆšåˆšä»Steveyçš„LLM Mini-Uæ¯•ä¸šï¼Œä½ æ‹¥æœ‰æ‰€æœ‰å¿…è¦çš„ç†è®ºèƒŒæ™¯æ¥æ¬£èµä¸ºä»€ä¹ˆæˆ‘è§‰å¾—è‡ªå·±æ˜¯åœ°çƒä¸Šæœ€å¹¸è¿çš„äººï¼Œä»¥åŠä¸ºä»€ä¹ˆæˆ‘æ­£åœ¨è¿™ç¯‡åšå®¢çš„ç¬¬2896é¡µä¸¾åŠæ´¾å¯¹ã€‚
- en: Because folks, I honestly donâ€™t know *how* I got so lucky. I joined Sourcegraph
    in September, not half so much for their product itself as for their Code Intelligence
    Platform, which was like [the one I built back at Google](https://www.youtube.com/watch?v=KTJs-0EInW8).
    Theyâ€™d nearly finished building [v1 of this platform](https://about.sourcegraph.com/blog/announcing-scip)
    and it was ready to start powering something amazing.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæœ‹å‹ä»¬ï¼Œè€å®è¯´ï¼Œæˆ‘çœŸçš„ä¸çŸ¥é“æˆ‘æ˜¯*æ€ä¹ˆ*è¿™ä¹ˆå¹¸è¿çš„ã€‚æˆ‘åœ¨ä¹æœˆä»½åŠ å…¥Sourcegraphï¼Œä¸ä»…ä»…æ˜¯å› ä¸ºä»–ä»¬çš„äº§å“æœ¬èº«ï¼Œæ›´æ˜¯å› ä¸ºä»–ä»¬çš„ä»£ç æ™ºèƒ½å¹³å°ï¼Œå°±åƒ[æˆ‘åœ¨Googleæ—¶æ„å»ºçš„é‚£ä¸ª](https://www.youtube.com/watch?v=KTJs-0EInW8)ã€‚ä»–ä»¬å‡ ä¹å®Œæˆäº†[v1ç‰ˆæœ¬çš„è¿™ä¸ªå¹³å°](https://about.sourcegraph.com/blog/announcing-scip)ï¼Œå®ƒå·²ç»å‡†å¤‡å¥½å¼€å§‹æ”¯æŒä¸€äº›ä»¤äººæƒŠå¥‡çš„ä¸œè¥¿ã€‚
- en: And then LLMs landed 10 weeks after I joined. The Singularity, the Cloverfield
    monster stomping around eating people, and everything else thatâ€™s happened since
    November 30th. Crazy town.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åLLMsåœ¨æˆ‘åŠ å…¥åçš„10å‘¨å†…ç™»åœºäº†ã€‚å¥‡ç‚¹ï¼Œå…‹æ´›å¼—è²å°”å¾·æ€ªå…½åœ¨å››å¤„è¸©è¸åé£Ÿäººç±»ï¼Œä»¥åŠè‡ª11æœˆ30æ—¥ä»¥æ¥å‘ç”Ÿçš„ä¸€åˆ‡ã€‚ç–¯ç‹‚çš„åŸé•‡ã€‚
- en: And what do LLMs need again? You, in the front row. Yeah, you.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£LLMså†æ¬¡éœ€è¦ä»€ä¹ˆï¼Ÿä½ ï¼Œåœ¨å‰æ’ã€‚æ˜¯çš„ï¼Œå°±æ˜¯ä½ ã€‚
- en: They need the data moat! The sidecar database. For populating the cheat sheet.
    Remember?
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬éœ€è¦æ•°æ®æŠ¤åŸæ²³ï¼è¾…åŠ©æ•°æ®åº“ã€‚ç”¨äºå¡«å……å¤‡å¿˜å•ã€‚è®°å¾—å—ï¼Ÿ
- en: Itâ€™s a Search problem. And Sourcegraph has spent the past *ten years* building
    the solution.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæœç´¢é—®é¢˜ã€‚è€ŒSourcegraphå·²ç»èŠ±äº†è¿‡å»*åå¹´*æ¥æ„å»ºè§£å†³æ–¹æ¡ˆã€‚
- en: Go figure.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ææ˜ç™½ã€‚
- en: 'Sourcegraphâ€™s platform has four enduring, difficult-to-reproduce dimensions
    that are incredibly relevant to the coding-assistant space:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Sourcegraphçš„å¹³å°å…·æœ‰å››ä¸ªæŒä¹…çš„ã€éš¾ä»¥å¤åˆ¶çš„ç»´åº¦ï¼Œè¿™äº›ç»´åº¦ä¸ç¼–ç åŠ©æ‰‹é¢†åŸŸå¯†åˆ‡ç›¸å…³ï¼š
- en: Itâ€™s **universal** and works across all code hosts and platforms.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯**é€šç”¨**çš„ï¼Œé€‚ç”¨äºæ‰€æœ‰ä»£ç ä¸»æœºå’Œå¹³å°ã€‚
- en: Itâ€™s **scalable** and ready for enterprises of all sizes.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯**å¯æ‰©å±•**çš„ï¼Œé€‚ç”¨äºå„ç§è§„æ¨¡çš„ä¼ä¸šã€‚
- en: Itâ€™s **precise** and comparable to IDEs in its accuracy and completeness.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯**ç²¾ç¡®**çš„ï¼Œä¸IDEåœ¨å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ä¸Šå¯æ¯”ã€‚
- en: Itâ€™s **open** and is being developed openly and transparently.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯**å¼€æ”¾**çš„ï¼Œå¹¶ä¸”æ­£åœ¨å…¬å¼€é€æ˜åœ°å¼€å‘ã€‚
- en: Sourcegraphâ€™s engine powers gigantic enterprises with literally a hundred thousand
    git repositories, and/or multi-terabyte massive megarepos that make IDEs fall
    over and puke. And at its core is an engine so powerful that maybe teaming up
    with an AI was its destiny all along.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Sourcegraphçš„å¼•æ“ä¸ºæ‹¥æœ‰æˆåƒä¸Šä¸‡ä¸ªgitä»“åº“å’Œ/æˆ–å¤šTBå¤§å‹è¶…çº§ä»“åº“çš„å·¨å¤§ä¼ä¸šæä¾›æ”¯æŒï¼Œè¿™äº›ä»“åº“è®©IDEå´©æºƒå’Œå‘•åã€‚è€Œå…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªå¦‚æ­¤å¼ºå¤§çš„å¼•æ“ï¼Œä¹Ÿè®¸ä¸AIåˆä½œä¸€ç›´æ˜¯å®ƒçš„å‘½è¿ã€‚
- en: Whoo boy. Did I get lucky? I think I got pretty lucky. We have such an incredible
    head-start in this race.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å“‡å“¦ã€‚æˆ‘æ˜¯ä¸æ˜¯å¾ˆå¹¸è¿ï¼Ÿæˆ‘è§‰å¾—æˆ‘å¾ˆå¹¸è¿ã€‚æˆ‘ä»¬åœ¨è¿™åœºæ¯”èµ›ä¸­æœ‰äº†å¦‚æ­¤ä»¤äººéš¾ä»¥ç½®ä¿¡çš„é¢†å…ˆä¼˜åŠ¿ã€‚
- en: When I say â€œWeâ€™re building a coding assistantâ€, I want you to think back to
    when Ruben Ortega showed us Amazonians his little demo of a remote procedure call
    over HTTP. That was Baby AWS.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘è¯´â€œæˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªç¼–ç åŠ©æ‰‹â€æ—¶ï¼Œæˆ‘å¸Œæœ›ä½ å›æƒ³ä¸€ä¸‹Ruben Ortegaå‘æˆ‘ä»¬äºšé©¬é€Šäººå±•ç¤ºè¿œç¨‹è¿‡ç¨‹è°ƒç”¨HTTPçš„å°æ¼”ç¤ºã€‚é‚£å°±æ˜¯Baby AWSã€‚
- en: 'Now take a look at what my esteemed colleague and Sourcegraph teammate Dominic
    Cooney slacked me last week:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨çœ‹çœ‹æˆ‘çš„å°Šæ•¬çš„åŒäº‹å’ŒSourcegraphé˜Ÿå‹Dominic Cooneyä¸Šå‘¨å‘ç»™æˆ‘çš„æ¶ˆæ¯ï¼š
- en: '*In other news, I am getting even more enthusiastic. There is more, much more,
    to this space than LLMs and I think we have the embryonic stage of some amazing
    invention here. Like some realizations that context provisioning is a service.
    That the output has streams, like one into the editor and one into the chat. That
    the LLM benefits from the opportunity to self criticize. That the UX needs diffs
    and in-situ things to home in on things. That search is as big a deal as chat.
    Many of our thumbs down reactions to [LLMs] come from them complaining they didn''t
    have the context of what language, file, codebase, etc. the user is talking about.
    Which bodes well because Sourcegraph should be able to do that really well.*'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦å¤–ï¼Œæˆ‘å˜å¾—æ›´åŠ çƒ­æƒ…ã€‚è¿™ä¸ªé¢†åŸŸæ¯”LLMsè¿˜è¦å¹¿é˜”å¾—å¤šï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬åœ¨è¿™é‡Œæœ‰ä¸€é¡¹äº†ä¸èµ·çš„å‘æ˜çš„èƒšèƒé˜¶æ®µã€‚æ¯”å¦‚ä¸€äº›å…³äºä¸Šä¸‹æ–‡æä¾›æ˜¯ä¸€é¡¹æœåŠ¡çš„è®¤è¯†ã€‚è¾“å‡ºæœ‰æµï¼Œæ¯”å¦‚ä¸€ä¸ªè¿›å…¥ç¼–è¾‘å™¨ï¼Œä¸€ä¸ªè¿›å…¥èŠå¤©ã€‚LLMå—ç›Šäºè‡ªæˆ‘æ‰¹è¯„çš„æœºä¼šã€‚ç”¨æˆ·ä½“éªŒéœ€è¦å·®å¼‚å’Œå°±åœ°äº‹ç‰©æ¥èšç„¦äº‹ç‰©ã€‚æœç´¢å’ŒèŠå¤©ä¸€æ ·é‡è¦ã€‚æˆ‘ä»¬å¯¹[LLMs]çš„è®¸å¤šæ‹’ç»ååº”æ¥è‡ªäºä»–ä»¬æŠ±æ€¨ä»–ä»¬ä¸çŸ¥é“ç”¨æˆ·åœ¨è°ˆè®ºä»€ä¹ˆè¯­è¨€ã€æ–‡ä»¶ã€ä»£ç åº“ç­‰ä¸Šä¸‹æ–‡ã€‚è¿™æ˜¯ä¸ªå¥½å…†å¤´ï¼Œå› ä¸º
    Sourcegraph åº”è¯¥èƒ½å¤Ÿåšå¾—å¾ˆå¥½ã€‚*'
- en: 'Heâ€™s glimpsed the future, and itâ€™s vast. His comment, â€œI think we have the
    embryonic stage of some amazing invention hereâ€, reminded me of all the embryonic
    stages Iâ€™ve seen of other eventually-amazing things: The Mosaic web browser. The
    mini-Borg demo that became Kubernetes. The Amazon web-services demo. The hanging-GET
    request in the browser.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ç¥è§äº†æœªæ¥ï¼Œè€Œä¸”æ˜¯å¹¿é˜”çš„ã€‚ä»–çš„è¯„è®ºï¼Œâ€œæˆ‘è®¤ä¸ºæˆ‘ä»¬åœ¨è¿™é‡Œæœ‰ä¸€é¡¹äº†ä¸èµ·çš„å‘æ˜çš„èƒšèƒé˜¶æ®µâ€ï¼Œè®©æˆ‘æƒ³èµ·äº†æˆ‘è§è¿‡çš„å…¶ä»–æœ€ç»ˆä»¤äººæƒŠå¹çš„äº‹ç‰©çš„èƒšèƒé˜¶æ®µï¼šMosaic
    ç½‘é¡µæµè§ˆå™¨ã€‚æˆä¸º Kubernetes çš„è¿·ä½  Borg æ¼”ç¤ºã€‚äºšé©¬é€Šç½‘ç»œæœåŠ¡æ¼”ç¤ºã€‚æµè§ˆå™¨ä¸­çš„ hanging-GET è¯·æ±‚ã€‚
- en: Little things grow up, folks!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å°äº‹æƒ…ä¼šå‘å±•å£®å¤§ï¼Œä¼™è®¡ä»¬ï¼
- en: Iâ€™ve seen this movie before. I know how it ends. This volcano is the big one.
    Skeptics beware. At the very least, I *hope* by now youâ€™re taking LLM-backed coding
    assistants in general just a teeny bit more seriously than you were an hour ago.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¥å‰çœ‹è¿‡è¿™éƒ¨ç”µå½±ã€‚æˆ‘çŸ¥é“ç»“å±€ã€‚è¿™åº§ç«å±±æ˜¯å¤§çš„é‚£ä¸€ä¸ªã€‚æ€€ç–‘è®ºè€…è¦å°å¿ƒäº†ã€‚è‡³å°‘ï¼Œ*å¸Œæœ›*ç°åœ¨ä½ å¯¹LLMæ”¯æŒçš„ç¼–ç åŠ©æ‰‹æ¯”ä¸€ä¸ªå°æ—¶å‰æ›´è®¤çœŸä¸€ç‚¹ã€‚
- en: OK, youâ€™ve heard the punchline, and the partyâ€™s in full swing. Lemme show you
    Cody and weâ€™ll call it a day.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œä½ å·²ç»å¬åˆ°äº†ç¬‘è¯ï¼Œæ´¾å¯¹æ­£åœ¨å…¨åŠ›è¿›è¡Œã€‚è®©æˆ‘å‘ä½ å±•ç¤º Codyï¼Œç„¶åæˆ‘ä»¬å°±æ”¶å·¥å§ã€‚
- en: '[](#a-whirlwind-tour-of-sourcegraphs-cody)A whirlwind tour of Sourcegraphâ€™s
    Cody'
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#a-whirlwind-tour-of-sourcegraphs-cody)Sourcegraph çš„ Cody ä¸€ç¥'
- en: 'Say hi to Cody:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ Cody æ‰“ä¸ªæ‹›å‘¼ï¼š
- en: '![Cody logo](../Images/be8675d40c33b24b4761d43e5b2d4c31.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![Cody æ ‡å¿—](../Images/be8675d40c33b24b4761d43e5b2d4c31.png)'
- en: Cody is Sourcegraphâ€™s new LLM-backed coding assistant. Cody knows about your
    code. It has templated actions, such as writing unit tests, generating doc comments,
    summarizing code, that kind of thing. You know. Stuff you can choose from a menu.
    Like other assistants. It even has code completions, if youâ€™re into that sort
    of thing.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Cody æ˜¯ Sourcegraph çš„æ–°çš„LLMæ”¯æŒçš„ç¼–ç åŠ©æ‰‹ã€‚Cody çŸ¥é“ä½ çš„ä»£ç ã€‚å®ƒæœ‰æ¨¡æ¿åŒ–çš„æ“ä½œï¼Œæ¯”å¦‚ç¼–å†™å•å…ƒæµ‹è¯•ï¼Œç”Ÿæˆæ–‡æ¡£æ³¨é‡Šï¼Œæ€»ç»“ä»£ç ï¼Œé‚£ç§ä¸œè¥¿ã€‚ä½ çŸ¥é“çš„ã€‚ä½ å¯ä»¥ä»èœå•ä¸­é€‰æ‹©çš„ä¸œè¥¿ã€‚å°±åƒå…¶ä»–åŠ©æ‰‹ä¸€æ ·ã€‚å¦‚æœä½ å–œæ¬¢çš„è¯ï¼Œå®ƒç”šè‡³æœ‰ä»£ç è¡¥å…¨åŠŸèƒ½ã€‚
- en: Cody is not some vague â€œrepresentation of a vision for the future of AIâ€. You
    can try it *[right now](https://about.sourcegraph.com/cody)*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Cody ä¸æ˜¯ä¸€ç§æ¨¡ç³Šçš„â€œä»£è¡¨æœªæ¥äººå·¥æ™ºèƒ½æ„¿æ™¯çš„è¡¨ç°â€ã€‚ä½ å¯ä»¥*ç«‹å³å°è¯•*å®ƒã€‚
- en: And it has a chat interface! Which means itâ€™s totally open-ended; you can ask
    it any question at all about your code base or your environment, and weâ€™ll send
    it the right cheat sheet. And Cody itself is a *platform*, because you can use
    it to build your own LLM-backed workflows.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿˜æœ‰ä¸€ä¸ªèŠå¤©ç•Œé¢ï¼è¿™æ„å‘³ç€å®ƒæ˜¯å®Œå…¨å¼€æ”¾çš„ï¼›ä½ å¯ä»¥é—®å®ƒå…³äºä½ çš„ä»£ç åº“æˆ–ç¯å¢ƒçš„ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä»¬ä¼šå‘é€ç»™å®ƒæ­£ç¡®çš„å¤‡å¿˜å•ã€‚è€Œ Cody æœ¬èº«æ˜¯ä¸€ä¸ª*å¹³å°*ï¼Œå› ä¸ºä½ å¯ä»¥ç”¨å®ƒæ¥æ„å»ºè‡ªå·±æ”¯æŒLLMçš„å·¥ä½œæµç¨‹ã€‚
- en: My favorite kind. Naturally.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æœ€å–œæ¬¢çš„ç±»å‹ã€‚å½“ç„¶ã€‚
- en: Currently Cody is a VSCode plugin, though weâ€™ll have it in other places soon
    enough.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼ŒCody æ˜¯ä¸€ä¸ª VSCode æ’ä»¶ï¼Œä¸è¿‡å¾ˆå¿«æˆ‘ä»¬ä¼šåœ¨å…¶ä»–åœ°æ–¹ä¹Ÿæ¨å‡ºå®ƒã€‚
- en: '![Using Cody in VS Code](../Images/623b3bb5f14a050a77167764dcd92864.png "Using
    Cody in VS Code")'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![åœ¨ VS Code ä¸­ä½¿ç”¨ Cody](../Images/623b3bb5f14a050a77167764dcd92864.png "åœ¨ VS
    Code ä¸­ä½¿ç”¨ Cody")'
- en: Cody scales up to the very biggest code bases in the world. And even though
    Cody is still a baby, just like Baby AWS back on Rubenâ€™s stinkpad in 2003, itâ€™s
    already able to lift a huge space rhino using only the power of the Force. Hang
    on, sorry wrong baby.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Cody èƒ½å¤Ÿæ‰©å±•åˆ°ä¸–ç•Œä¸Šæœ€å¤§çš„ä»£ç åº“ã€‚å°½ç®¡ Cody è¿˜æ˜¯ä¸€ä¸ªå©´å„¿ï¼Œå°±åƒ 2003 å¹´åœ¨ Ruben çš„è‡­å«å­ä¸Šçš„ Baby AWS ä¸€æ ·ï¼Œå®ƒå·²ç»èƒ½å¤Ÿä»…å‡­åŸåŠ›çš„åŠ›é‡ä¸¾èµ·ä¸€åªå·¨å¤§çš„å¤ªç©ºçŠ€ç‰›ã€‚ç­‰ç­‰ï¼ŒæŠ±æ­‰ï¼Œæé”™äº†å©´å„¿ã€‚
- en: Ahem. As I was saying, like Baby AWS, Cody is *also* a baby with special powers,
    and honestlyâ€¦ we donâ€™t know how powerful itâ€™s going to get. It seems to be accelerating,
    if anything.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: å•Šå—¯ã€‚å°±åƒæˆ‘è¯´çš„ï¼Œå°±åƒBaby AWSä¸€æ ·ï¼ŒCodyä¹Ÿæ˜¯ä¸€ä¸ªå…·æœ‰ç‰¹æ®Šèƒ½åŠ›çš„å©´å„¿ï¼Œè€å®è¯´...æˆ‘ä»¬ä¸çŸ¥é“å®ƒä¼šå˜å¾—å¤šä¹ˆå¼ºå¤§ã€‚å¦‚æœæœ‰çš„è¯ï¼Œå®ƒä¼¼ä¹æ­£åœ¨åŠ é€Ÿã€‚
- en: Oh, and anyone can ~~sign up to get access~~ [start using Cody now](https://cody.dev).
    *(Edited after Cody was released.)*
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å“¦ï¼Œä»»ä½•äººéƒ½å¯ä»¥~~æ³¨å†Œè·å–è®¿é—®æƒé™~~[ç«‹å³å¼€å§‹ä½¿ç”¨Cody](https://cody.dev)ã€‚*ï¼ˆCodyå‘å¸ƒåç¼–è¾‘ã€‚ï¼‰*
- en: 'OK so anyway hereâ€™s how Cody works:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œæ— è®ºå¦‚ä½•è¿™å°±æ˜¯Codyçš„å·¥ä½œæ–¹å¼ï¼š
- en: '![A diagram of how Cody works](../Images/d22765134f48c8e42c6bdfa2b9c42e88.png
    "A diagram of how Cody works")'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![Codyå·¥ä½œåŸç†çš„å›¾è¡¨](../Images/d22765134f48c8e42c6bdfa2b9c42e88.png "Codyå·¥ä½œåŸç†çš„å›¾è¡¨")'
- en: 'Hereâ€™s the diagram above, in a nutshell:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä¸Šé¢çš„å›¾è¡¨çš„è¦ç‚¹ï¼š
- en: '**You ask Cody to do something** (for instance, â€œwrite a unit test for this
    functionâ€)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½ è¦æ±‚CodyåšæŸäº‹**ï¼ˆä¾‹å¦‚ï¼Œâ€œä¸ºè¿™ä¸ªå‡½æ•°ç¼–å†™ä¸€ä¸ªå•å…ƒæµ‹è¯•â€ï¼‰'
- en: '**Cody populates the cheat sheet** / context window query using Sourcegraphâ€™s
    code intelligence platform (search queries, embeddings retrievals, graphql queries,
    etc)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Codyå¡«å……å¤‡å¿˜å•** / ä¸Šä¸‹æ–‡çª—å£æŸ¥è¯¢ï¼Œä½¿ç”¨Sourcegraphçš„ä»£ç æ™ºèƒ½å¹³å°ï¼ˆæœç´¢æŸ¥è¯¢ã€åµŒå…¥æ£€ç´¢ã€graphqlæŸ¥è¯¢ç­‰ï¼‰'
- en: '**It sends the context+query to the LLM**, and parses the results'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®ƒå°†ä¸Šä¸‹æ–‡+æŸ¥è¯¢å‘é€åˆ°LLM**ï¼Œå¹¶è§£æç»“æœ'
- en: '**It optionally inserts the results back** into the IDE (depending on the action)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®ƒå¯é€‰æ‹©å°†ç»“æœæ’å…¥**å›IDEï¼ˆå–å†³äºæ“ä½œï¼‰'
- en: And of course this is all just the veeeery beginning. This thing will grow into
    a goliath that enhances everything you do as an engineer.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œè¿™åªæ˜¯ä¸€ä¸ªéå¸¸åˆæ­¥çš„é˜¶æ®µã€‚è¿™ä¸ªä¸œè¥¿å°†æˆé•¿ä¸ºä¸€ä¸ªå¢å¼ºä½ ä½œä¸ºå·¥ç¨‹å¸ˆæ‰€åšçš„ä¸€åˆ‡çš„å·¨äººã€‚
- en: Other coding assistants, which do not have Sourcegraph for Step 2 (populating
    the context), are stuck using whatever context they can get from the IDE. But
    sadly for them, IDEs werenâ€™t really designed with this use case in mind, and they
    make it difficult. And more damningly, no IDE scales up to industrial-sized code
    bases.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä»–ç¼–ç åŠ©æ‰‹ï¼Œåœ¨ç¬¬2æ­¥ï¼ˆå¡«å……ä¸Šä¸‹æ–‡ï¼‰ä¸­æ²¡æœ‰Sourcegraphçš„æƒ…å†µä¸‹ï¼Œè¢«å›°åœ¨ä½¿ç”¨IDEä¸­èƒ½è·å–çš„ä»»ä½•ä¸Šä¸‹æ–‡ä¸­ã€‚ä½†å¯¹äºä»–ä»¬æ¥è¯´ï¼Œé—æ†¾çš„æ˜¯ï¼ŒIDEå¹¶æ²¡æœ‰çœŸæ­£è€ƒè™‘åˆ°è¿™ç§ç”¨ä¾‹ï¼Œå¹¶ä¸”ä½¿å…¶å˜å¾—å›°éš¾ã€‚æ›´ä»¤äººæ²®ä¸§çš„æ˜¯ï¼Œæ²¡æœ‰ä¸€ä¸ªIDEèƒ½å¤Ÿæ‰©å±•åˆ°å·¥ä¸šè§„æ¨¡çš„ä»£ç åº“ã€‚
- en: So itâ€™s just plain unfair. Iâ€™m just gonna call it like it is. Sourcegraph has
    an absolutely unfair advantage, which they built up over *ten years* of building
    out this incredibly scalable, precise, and comprehensive code intelligence platform,
    powered by a world-class search engine and code knowledge graph.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯çº¯ç²¹çš„ä¸å…¬å¹³ã€‚æˆ‘å°±ç›´è¯´å§ã€‚Sourcegraphæ‹¥æœ‰ç»å¯¹ä¸å…¬å¹³çš„ä¼˜åŠ¿ï¼Œä»–ä»¬åœ¨*åå¹´*çš„æ—¶é—´é‡Œå»ºç«‹äº†è¿™ä¸ªéå¸¸å¯æ‰©å±•ã€ç²¾ç¡®å’Œå…¨é¢çš„ä»£ç æ™ºèƒ½å¹³å°ï¼Œç”±ä¸–ç•Œä¸€æµçš„æœç´¢å¼•æ“å’Œä»£ç çŸ¥è¯†å›¾æ”¯æŒã€‚
- en: Did I mention Iâ€™m lucky? Iâ€™m so fortunate to be here, and grateful to be part
    of this team.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æœ‰æåˆ°æˆ‘å¾ˆå¹¸è¿å—ï¼Ÿæˆ‘å¾ˆå¹¸è¿èƒ½åœ¨è¿™é‡Œï¼Œä¹Ÿå¾ˆæ„Ÿæ¿€èƒ½æˆä¸ºè¿™ä¸ªå›¢é˜Ÿçš„ä¸€éƒ¨åˆ†ã€‚
- en: '[](#afterlogue)Afterlogue'
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[](#afterlogue)åè®°'
- en: I donâ€™t really know how to finish this post. Are we there yet? Iâ€™ve tried to
    write this thing 3 times now, and it looks like I may have finally made it. I
    aimed for 5 pages, deliberately under-explained everything, and itâ€™sâ€¦ fifteen.
    Sigh.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çœŸçš„ä¸çŸ¥é“å¦‚ä½•ç»“æŸè¿™ç¯‡æ–‡ç« ã€‚æˆ‘ä»¬åˆ°äº†å—ï¼Ÿæˆ‘å·²ç»å°è¯•å†™äº†è¿™ç¯‡æ–‡ç« 3æ¬¡äº†ï¼Œçœ‹èµ·æ¥æˆ‘å¯èƒ½ç»ˆäºå®Œæˆäº†ã€‚æˆ‘æœ¬æ¥æƒ³å†™5é¡µï¼Œæ•…æ„å¯¹ä¸€åˆ‡è¿›è¡Œç®€è¦è§£é‡Šï¼Œç»“æœ...å˜æˆäº†åäº”é¡µã€‚å¹æ°”ã€‚
- en: But hopefully you got the main takeaways. Baby AWS. Knee jerking. Meh-nadoes.
    Cheat sheets. Data moats. Cody. You got this!
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å¸Œæœ›ä½ èƒ½å¾—åˆ°ä¸»è¦çš„è¦ç‚¹ã€‚Baby AWSã€‚è†è·³ã€‚Meh-nadoesã€‚å¤‡å¿˜å•ã€‚æ•°æ®å£•æ²Ÿã€‚Codyã€‚ä½ èƒ½åšåˆ°ï¼
- en: LLMs arenâ€™t some dumb fad, like crypto. Yes, crypto was a dumb fad. This is
    not that.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: LLMä¸æ˜¯åƒåŠ å¯†è´§å¸é‚£æ ·çš„æ„šè ¢æ½®æµã€‚æ˜¯çš„ï¼ŒåŠ å¯†è´§å¸æ˜¯ä¸€ä¸ªæ„šè ¢çš„æ½®æµã€‚è¿™ä¸æ˜¯é‚£æ ·çš„ã€‚
- en: Coding assistants are coming. Theyâ€™re imminent. You will use them this year.
    They will absolutely blow your mind. And theyâ€™ll continue to improve at an astonishing
    rate.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–ç åŠ©æ‰‹å³å°†åˆ°æ¥ã€‚å®ƒä»¬å³å°†åˆ°æ¥ã€‚ä»Šå¹´ä½ å°†ä¼šä½¿ç”¨å®ƒä»¬ã€‚å®ƒä»¬ç»å¯¹ä¼šè®©ä½ å¤§åƒä¸€æƒŠã€‚è€Œä¸”å®ƒä»¬å°†ç»§ç»­ä»¥æƒŠäººçš„é€Ÿåº¦æ”¹è¿›ã€‚
- en: They will feel gloriously like cheating, just like when IDEs came out, back
    in the days of yore. And for a time-constrained developer like meâ€“and I say this
    as someone who has written over a million lines of production codeâ€¦
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬ä¼šè®©ä½ æ„Ÿè§‰åƒåœ¨ä½œå¼Šï¼Œå°±åƒå½“IDEå‡ºç°æ—¶ä¸€æ ·ï¼Œåœ¨å¤è€çš„æ—¥å­é‡Œã€‚å¯¹äºåƒæˆ‘è¿™æ ·æ—¶é—´å—é™çš„å¼€å‘äººå‘˜â€”â€”æˆ‘è¯´è¿™è¯æ˜¯ä½œä¸ºä¸€ä¸ªå†™è¿‡ä¸€ç™¾ä¸‡è¡Œç”Ÿäº§ä»£ç çš„äºº...
- en: Cheating is all you need.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œå¼Šå°±æ˜¯ä½ éœ€è¦çš„ä¸€åˆ‡ã€‚
- en: Thanks for reading, and if you like, come be our [Head of AI](https://boards.greenhouse.io/sourcegraph91/jobs/4803652004)!
    Or come do [something else](https://boards.greenhouse.io/sourcegraph91) with us!
    Itâ€™s pretty merry around here already, but the more, the merrier.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼Œå¦‚æœä½ æ„¿æ„ï¼Œæ¥æˆä¸ºæˆ‘ä»¬çš„[AIä¸»ç®¡](https://boards.greenhouse.io/sourcegraph91/jobs/4803652004)å§ï¼æˆ–è€…å’Œæˆ‘ä»¬ä¸€èµ·åš[å…¶ä»–äº‹æƒ…](https://boards.greenhouse.io/sourcegraph91)ï¼è¿™é‡Œå·²ç»å¾ˆæ„‰å¿«äº†ï¼Œä½†è¶Šå¤šäººè¶Šå¿«ä¹ã€‚
